{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear Discriminant Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(dataset_path, file_type=\"txt\"):\n",
    "    if file_type == \"txt\":\n",
    "        X = []                                                       ### create feature matrix\n",
    "        y = []                                                       ### create label matrix\n",
    "        fr = open(dataset_path)                                      ### open file\n",
    "        for line in fr.readlines():                                  ### read datum\n",
    "            lineArr = line.strip().split()                           ### remove the `\\n` and obtain the data from string\n",
    "            X.append([float(x) for x in lineArr[:-1]])               ### add to the feature matrix\n",
    "            y.append(float(lineArr[-1]))                             ### add to the label matrix\n",
    "        fr.close()                                                   ### close file\n",
    "        return X, y \n",
    "\n",
    "# read the data\n",
    "import numpy as np\n",
    "X_train, y_train = loadDataSet(\"horseColicTraining.txt\")\n",
    "X_test, y_test = loadDataSet(\"horseColicTest.txt\")\n",
    "\n",
    "# transform the data from list to np.array\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# normalize\n",
    "X = np.vstack([X_train, X_test])\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA(object):\n",
    "    '''\n",
    "    This class is for linear discriminant analysis classification.\n",
    "    \n",
    "    The class contains the parameters of LDA, including the number of classes and the prior probability p(i) of \n",
    "    each class $i$, where $i=1,2,\\ldots,num_classes$. Moreover, the class contains the the mean vectors $\\mu_i$ \n",
    "    and covariance matrix $\\Sigma$ of probability distributions $p(x|i)$ for the class $i$.\n",
    "    \n",
    "    It also contains the functions for initializing the class, fitting the LDA classifier model, use \n",
    "    the fitted model to calculate the linear discriminant functions $\\delta_i(x)$ and decision function $h^*(x)$.\n",
    "    \n",
    "    Attributes:\n",
    "        mu (matrix, num_classes*num_features)    : mean vectors of distributions $p(x|i)$. The $i$-th row represents $\\mu_i$.\n",
    "        Sigma (matrix, num_features*num_features): covariance matrix\n",
    "        num_classes (positive integer)           : the number of classes\n",
    "        priorProbs (vector, num_classes)         : the prior probability vector and its $i$-th element is $p(i)$\n",
    "        \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Initialize the class by just assigning zero to all atrributes. \n",
    "        '''\n",
    "        self.mu = 0 \n",
    "        self.Sigma = 0\n",
    "        self.num_classes = 0\n",
    "        self.priorProbs = 0\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        estimate the mean vector and covariance matrix of each class in the LDA model\n",
    "        \n",
    "        Args: \n",
    "            X (matrix, num_train*num_features): features of training samples\n",
    "            y (matrix, num_train): label of training samples\n",
    "            \n",
    "        Returns:\n",
    "            mu (matrix, num_classes*num_features)    : mean vectors of distributions $p(x|i)$. The $i$-th row represents $\\mu_i$.\n",
    "            Sigma (matrix, num_features*num_features): covariance matrix\n",
    "        ''' \n",
    "        num_samples, num_features = X.shape\n",
    "        values, counts = np.unique(y, return_counts = True)\n",
    "        num_classes = len(values)\n",
    "        ### calculate the prior probability $p(i)$\n",
    "        self.priorProbs = counts / num_samples\n",
    "        ### calculate the mean vector of each class $\\mu_i$\n",
    "        self.mu = np.zeros((num_classes, num_features))\n",
    "        for k in range(num_samples):\n",
    "            self.mu[int(y[k]),:] += X[k,:]\n",
    "        self.mu = self.mu / np.expand_dims(counts, 1) \n",
    "        ### calculate the covariance matrix $\\Sigma$\n",
    "        Sigma_i = [np.cov(X[y == i].T)*(X[y == i].shape[0]-1) for i in range(num_classes)] \n",
    "        self.Sigma = sum(Sigma_i) / (X.shape[0]-num_classes)\n",
    "        return self.mu, self.Sigma\n",
    "    \n",
    "    def linear_discriminant_func(self, X):\n",
    "        '''\n",
    "        calculate the linear discriminant functions $\\delta_i(X)$\n",
    "        \n",
    "        Args: \n",
    "            X (matrix, num_samples*num_features): features of samples\n",
    "            \n",
    "        Returns:\n",
    "            value (matrix, num_samples*num_classes): the linear discriminant function values. \n",
    "            The $(j,i)$-th entry of value represents $\\delta_i(X[j,:])$, which is the linear discriminant function value for the class $i$ of the sample at row $j$.\n",
    "        '''\n",
    "        ### calculate the inverse matrix of the covariance matrix $\\Sigma$\n",
    "        U, S, V = np.linalg.svd(self.Sigma)\n",
    "        Sn = np.linalg.inv(np.diag(S))\n",
    "        Sigma_inv = np.dot(np.dot(V.T, Sn), U.T)\n",
    "        ### calculate the linear discriminant function values of X\n",
    "        value = np.dot(np.dot(X, Sigma_inv), self.mu.T) - \\\n",
    "                0.5 * np.multiply(np.dot(self.mu, Sigma_inv).T, self.mu.T).sum(axis = 0).reshape(1, -1) + \\\n",
    "                np.log(np.expand_dims(self.priorProbs, axis = 0))\n",
    "        return value\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        calculate the linear discriminant functions\n",
    "        \n",
    "        Args: \n",
    "            X (matrix, num_samples*num_features): features of samples\n",
    "            \n",
    "        Returns:\n",
    "            pred_label (vector, num_samples): the predicted labels of samples. The $j$-th entry represents the predicted label of the sample at row $j$.\n",
    "        '''\n",
    "        pred_value = self.linear_discriminant_func(X)\n",
    "        pred_label = np.argmax(pred_value, axis = 1)\n",
    "        return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LDA on the test dataset is 0.7313432835820896.\n"
     ]
    }
   ],
   "source": [
    "### initiate the LDA model\n",
    "model = LDA()\n",
    "### fit the model with training data and get the estimation of mu and Sigma\n",
    "mu, Sigma = model.fit(X_train, y_train)\n",
    "### predict the label of test data\n",
    "y_pred = model.predict(X_test)\n",
    "### calculate the accuracy of the fitted LDA model on test data\n",
    "accuracy = np.sum(y_pred == y_test)/len(y_test)\n",
    "print(\"Accuracy of LDA on the test dataset is {}.\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
