{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Naive Bayes\n",
    "\n",
    "We are going to classify sentences with Naive Bayes algorithm. We have some abusive and not abusive sentences in the form of word lists. Our task is to predict whether a new sentence is abusive or not.\n",
    "\n",
    "\n",
    "## 1.1 Prepare: transform sentences into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    ### Each sentence appears in the form of word list.\n",
    "    postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],       \n",
    "                 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                 ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    ### Labels of sentences. 1 is abusive, 0 not\n",
    "    classVec = [0,1,0,1,0,1]\n",
    "    return postingList,classVec\n",
    "\n",
    "# create a list of the unique words in all sentences.\n",
    "def createVocabList(dataSet):\n",
    "    vocabSet = set([])    #Create an empty set\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document) #Create the union of two sets\n",
    "    return list(vocabSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary list is:\n",
      " ['steak', 'is', 'quit', 'to', 'mr', 'problems', 'love', 'ate', 'help', 'cute', 'I', 'licks', 'posting', 'garbage', 'take', 'not', 'park', 'so', 'food', 'worthless', 'stop', 'dog', 'maybe', 'how', 'please', 'flea', 'has', 'my', 'dalmation', 'him', 'stupid', 'buying']\n"
     ]
    }
   ],
   "source": [
    "postingList, classVec = loadDataSet()\n",
    "myVocabList = createVocabList(postingList)\n",
    "print('The vocabulary list is:\\n', myVocabList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    '''\n",
    "    According to vocabulary list (vocabList), we convert a word vector (inputSet) to a vector of 1s and 0s of the \n",
    "    same length as the vocabulary list. \n",
    "    The $i$-th element of output vector represents whether the $i$-th word in our vocabulary list is present or not in \n",
    "    the word vector.\n",
    "    \n",
    "    Args:\n",
    "        vocabList - a vocabulary list\n",
    "        inputSet - a word list\n",
    "    Returns:\n",
    "        returnVec - a vector of 1s and 0s of the same length as the vocabulary list\n",
    "    '''\n",
    "    returnVec = [0] * len(vocabList)                               #Create a vector of all 0s\n",
    "    for word in inputSet:                                          \n",
    "        if word in vocabList:                                      #If the word is in the vocabulary list，then we set its value to 1 in the output vector.\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "        else: print(\"the word: %s is not in my Vocabulary!\" % word)\n",
    "    return returnVec                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0-1 vector of the first sentence is: [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "trainMat = []\n",
    "for postinDoc in postingList:\n",
    "    trainMat.append(setOfWords2Vec(myVocabList, postinDoc))\n",
    "print('The 0-1 vector of the first sentence is:', trainMat[0])\n",
    "print(len(trainMat[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Implement the class of Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class NaiveBayes():\n",
    "    '''\n",
    "    This is a class for Naive Bayes classification.\n",
    "    \n",
    "    The class contains the arrays of conditional probabilities for abusive class and not abusive class.\n",
    "    \n",
    "    It also contains the functions for initializing the class, fitting the Naive Bayes classifier model and use \n",
    "    the fitted model to predict test samples.\n",
    "    \n",
    "    Attributes:\n",
    "        p0Vect (vector, num_sentences)   - array of conditional probabilities for abusive class\n",
    "        p1Vect (vector, num_sentences) - array of conditional probabilities for not abusive class\n",
    "        pAbusive (number in [0,1])  - the probability that the document belongs to the abusive class\n",
    "        \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.p1Vect = 0\n",
    "        self.p0Vect = 0\n",
    "        self.pAbusive = 0\n",
    "        \n",
    "    def fit(self, trainMatrix, classVec):\n",
    "        '''\n",
    "        fit the naive Bayes classifier to the training data. To be specific, we calculate the class-conditional \n",
    "        probability $p(x_j|c)$ and $p(c)$.\n",
    "\n",
    "        Args:\n",
    "            trainMatrix (matrix, num_sentences * num_vocablist) : sentence matrix, returned by the function setOfWords2Vec()\n",
    "            classVec (vector, num_sentences)                    : label vector，returned by the function loadDataSet()\n",
    "        Returns:\n",
    "            p0Vect (vector, num_sentences)   - array of conditional probabilities for abusive class\n",
    "            p1Vect (vector, num_sentences) - array of conditional probabilities for not abusive class\n",
    "            pAbusive (number in [0,1])  - the probability that the document belongs to the abusive class\n",
    "        '''\n",
    "        numTrainDocs = len(trainMatrix)                       \n",
    "        numWords = len(trainMatrix[0])                        \n",
    "        self.pAbusive = sum(classVec)/numTrainDocs     \n",
    "        ### Create numpy.ones array, the number of appearance of all words is initialized to 1 due to Laplacian smoothing\n",
    "        p0Num = np.ones(numWords); p1Num = np.ones(numWords)  \n",
    "        ### The denominator is initialized to 2 due to Laplacian smoothing.\n",
    "        p0Denom = 2.0; p1Denom = 2.0                          \n",
    "        ### Calculate the probablities of appearance of all vocabulary words for the abusive and non-abusive class.\n",
    "        for i in range(numTrainDocs):\n",
    "            ### Update p1Num, p1Denom, p0Num, p0Denom\n",
    "            if classVec[i] == 1:   \n",
    "                p1Num += trainMatrix[i]\n",
    "                p1Denom += sum(trainMatrix[i])\n",
    "            else:                      \n",
    "                p0Num += trainMatrix[i]\n",
    "                p0Denom += sum(trainMatrix[i])\n",
    "        self.p1Vect = p1Num/p1Denom\n",
    "        self.p0Vect = p0Num/p0Denom\n",
    "        return self.p0Vect, self.p1Vect, self.pAbusive\n",
    "    \n",
    "\n",
    "    def predict(self, vec2Classify):\n",
    "        '''\n",
    "        Args:\n",
    "            vec2Classify - the word list (or sentence) to be classfied\n",
    "        Returns:\n",
    "            0/1 - classified as not abusive/abusive\n",
    "        '''\n",
    "        logp1Vect = np.log(self.p1Vect)                     \n",
    "        logp0Vect = np.log(self.p0Vect)\n",
    "        p1 = np.sum(vec2Classify * logp1Vect) + np.log(self.pAbusive)       \n",
    "        p0 = np.sum(vec2Classify * logp0Vect) + np.log(1.0 - self.pAbusive)\n",
    "        if p1 > p0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0V:\n",
      " [0.07692308 0.07692308 0.07692308 0.03846154 0.07692308 0.07692308\n",
      " 0.07692308 0.07692308 0.03846154 0.03846154 0.07692308 0.15384615\n",
      " 0.07692308 0.03846154 0.07692308 0.07692308 0.07692308 0.07692308\n",
      " 0.07692308 0.03846154 0.11538462 0.03846154 0.07692308 0.07692308\n",
      " 0.03846154 0.07692308 0.07692308 0.03846154 0.03846154 0.03846154\n",
      " 0.07692308 0.03846154]\n",
      "p1V:\n",
      " [0.14285714 0.04761905 0.04761905 0.0952381  0.0952381  0.04761905\n",
      " 0.04761905 0.04761905 0.0952381  0.0952381  0.04761905 0.04761905\n",
      " 0.04761905 0.0952381  0.04761905 0.04761905 0.0952381  0.04761905\n",
      " 0.04761905 0.0952381  0.0952381  0.0952381  0.04761905 0.04761905\n",
      " 0.19047619 0.04761905 0.04761905 0.0952381  0.0952381  0.14285714\n",
      " 0.04761905 0.0952381 ]\n",
      "pAbusive:\n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "NBmodel = NaiveBayes()\n",
    "p0V, p1V, pAb = NBmodel.fit(trainMat, classVec)\n",
    "print('p0V:\\n', p0V)\n",
    "print('p1V:\\n', p1V)\n",
    "print('pAbusive:\\n', pAb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Predict the new sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'my', 'dalmation'] is classified as: 0\n",
      "['stupid', 'garbage'] is classified as: 1\n"
     ]
    }
   ],
   "source": [
    "testEntry = ['love', 'my', 'dalmation']\n",
    "thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))\n",
    "print('{} is classified as: {}'.format(testEntry, NBmodel.predict(thisDoc)))\n",
    "\n",
    "testEntry = ['stupid', 'garbage']\n",
    "thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry))\n",
    "print('{} is classified as: {}'.format(testEntry, NBmodel.predict(thisDoc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
