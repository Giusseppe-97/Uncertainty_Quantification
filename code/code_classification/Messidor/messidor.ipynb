{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetic Retinopathy Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a nutshell, DR is a eye complication that affects around 40% of people with diabetes, leading to blindness. If detected in time can be slowed down. \n",
    "This dataset is composed of features extracted from the output of several retinal image processing algorithms, such as:\n",
    "- imagelevel (quality assessment, pre-screening, AM/FM)\n",
    "- lesion-specific (microaneurysms, exudates) \n",
    "- anatomical (macula, optic disc) components. \n",
    "The actual decision about the presence of the disease is then made by comparing machine learning classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, I am going to compare three different classifier algorithms: logistic regression, Support vector machine and random forest. I am firstly going to use the tools and codes from the tutorials. After achiving a seeminly optimistic result, I will compare it to the outcome of the sklearn library. Finally, I will summarize my results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from encodings import search_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import necessary tools from the sklearn library\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "# Import sklearn library tools used ONLY for validating my results\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, f1_score, accuracy_score, recall_score, precision_score, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import randint as sp_randint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets function\n",
    "def load_data(data_file_name):\n",
    "    data_dir = \"..\\..\\..\\data\\data_classification\"\n",
    "    data_path = os.path.join(data_dir, data_file_name)\n",
    "    df = pd.read_csv(data_path)\n",
    "    data_X = df.iloc[:,:-1]\n",
    "    data_y = df.iloc[:,-1]\n",
    "    scaler_X = StandardScaler()\n",
    "    data_X = scaler_X.fit_transform(data_X)\n",
    "    data_y = pd.Categorical(data_y).codes.reshape(-1)\n",
    "    return data_X, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # read dataset from csv file\n",
    "    data_name = \"messidor_classification\"\n",
    "    data_X, data_y = load_data(\"{}.csv\".format(data_name))\n",
    "\n",
    "    # Randomly assingning a train and test set\n",
    "    train_X, test_X, train_y, test_y = train_test_split(data_X, data_y, test_size=0.33, random_state=2200)\n",
    "    return train_X, test_X, train_y, test_y, data_X, data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression:\n",
    "    '''\n",
    "    This is a class for Logistic Regression algorithm.\n",
    "    \n",
    "    The class contains the hyper parameters of the logistic regression algorithm as attributes.\n",
    "    It also contains the functions for initializing the class, fitting the ridge regression model and use the fitted \n",
    "    model to predict test samples.\n",
    "    \n",
    "    Attributes:\n",
    "        lr:        learning rate of gradient descent\n",
    "        max_itr:   maximum number of iteration for gradient descent\n",
    "        tol:       if the change in loss is smaller than tol, then we stop iteration\n",
    "        W:         concatenation of weight w and bias b\n",
    "        verbose:   whether or not print the value of logitic loss every 1000 iterations\n",
    "        \n",
    "    '''\n",
    "    def __init__(self, lr=0.01, max_itr=100000, tol = 1e-5, verbose = False):\n",
    "        self.lr = lr\n",
    "        self.max_itr = max_itr\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    " \n",
    "    def __sigmoid(self, z):\n",
    "        '''\n",
    "        Define the Sigmoid function to convert from real value to [0,1]\n",
    "        \n",
    "        Args: \n",
    "            z (matrix, num_samples*1): scores or real value\n",
    "            \n",
    "        Returns:\n",
    "            A matrix (num_variables+1)*1: a value in the interval [0,1]\n",
    "        '''\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def __logistic_loss(self, h, y):\n",
    "        '''\n",
    "        Calculate the logistic loss\n",
    "        '''\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        '''\n",
    "        estimate the weight and bias in the logistic regression model by gradient descent\n",
    "        \n",
    "        Args: \n",
    "            x (matrix, num_train*num_variables): input of training samples\n",
    "            y (matrix, num_test*1): labels of training samples, 0 or 1\n",
    "            \n",
    "        Returns:\n",
    "            self.W (matrix, (num_variables+1)*1): estimation of weight and bias, i.e (w,b)\n",
    "        '''\n",
    "        ### Add the all-one vector to the last column \n",
    "        m = x.shape[0]\n",
    "        X = np.concatenate((x, np.ones((m, 1))), axis=1)\n",
    "        y = y.reshape(-1,1)\n",
    "        # weight and bias initialization\n",
    "        d = X.shape[1]\n",
    "        self.W = np.zeros((d,1))\n",
    "        \n",
    "        z = np.dot(X, self.W)\n",
    "        h = self.__sigmoid(z)\n",
    "        previous_loss = self.__logistic_loss(h, y)\n",
    "        for i in range(self.max_itr):\n",
    "            ######################################\n",
    "            ######################################\n",
    "            ####### Write your codes below #######\n",
    "            ### Calculate the gradient and update self.W\n",
    "            p1 = np.divide(np.exp(np.dot(X, self.W)),(1+np.exp(np.dot(X,self.W))))\n",
    "            \n",
    "            grad = - 1/m * (np.dot(np.transpose(X),y-p1))\n",
    "\n",
    "            self.W = self.W - self.lr * grad\n",
    "\n",
    "            ######################################\n",
    "            ######################################\n",
    "            \n",
    "            #Calculate the new logistic loss\n",
    "            z = np.dot(X, self.W)\n",
    "            h = self.__sigmoid(z)\n",
    "            current_loss = self.__logistic_loss(h, y)\n",
    "            if previous_loss - current_loss < self.tol:\n",
    "                print('Converged after {} iterations'.format(i+1))\n",
    "                print('Logistic loss after {} iterations is {}'.format(i+1,current_loss))\n",
    "                break\n",
    "            else:\n",
    "                previous_loss = current_loss\n",
    "            if(self.verbose == True and i % 10000 == 0):\n",
    "                print('Logistic loss after {} iterations is {}'.format(i+1,current_loss))\n",
    "        return self.W\n",
    "    \n",
    "    def predict_prob(self, x):\n",
    "        '''\n",
    "        predict the posterior probability p_1(x; W) of the test samples\n",
    "        \n",
    "        Args: \n",
    "            x (matrix, num_test*num_variables): input of test samples\n",
    "            \n",
    "        Returns:\n",
    "            y (matrix, num_test*1): predicted posterior probability p_1(x; W) of test samples\n",
    "        ''' \n",
    "        ######################################\n",
    "        ######################################\n",
    "        ####### Write your codes below #######\n",
    "        m = x.shape[0]\n",
    "        X = np.concatenate((x,np.ones((m,1))),axis=1)    \n",
    "        y = np.divide(np.exp(np.dot(X, self.W)),(1+np.exp(np.dot(X,self.W))))\n",
    "        \n",
    "        return y\n",
    "        ######################################\n",
    "        ######################################\n",
    "    \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        predict the label of the test samples\n",
    "        \n",
    "        Args: \n",
    "            x (matrix, num_test*num_variables): input of test samples\n",
    "            \n",
    "        Returns:\n",
    "            y (matrix, num_test*1): predicted labels of test samples, 0 or 1\n",
    "        ''' \n",
    "        ######################################\n",
    "        ######################################\n",
    "        ####### Write your codes below #######\n",
    "        m = x.shape[0]\n",
    "        X = np.concatenate((x,np.ones((m,1))),axis=1)\n",
    "        y = 1 / (1 + np.exp(-np.dot(X,self.W)))\n",
    "        y = np.where(y>0.5,1,0)\n",
    "        \n",
    "        return y\n",
    "        ######################################\n",
    "        ######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    ### initiate the logistic regressor\n",
    "    model = MyLogisticRegression(lr=0.1, max_itr=1000000, tol = 1e-8, verbose=True)\n",
    "\n",
    "    ### fit the model with training data and get the estimation of parameters (w & b)\n",
    "    W = model.fit(main()[0], main()[2])\n",
    "\n",
    "    ### Print the estimated w and b\n",
    "    print(W.T)\n",
    "\n",
    "    ### Print the estimated w and b\n",
    "    print(\"The weight w of LR is \\n {}.\".format(W[:main()[1].shape[1],0].T))\n",
    "    print(\"The bias b of LR is {}.\".format(W[main()[1].shape[1],0]))\n",
    "\n",
    "    y_pred = model.predict(main()[1])\n",
    "    accuracy = np.sum(y_pred[:,0] == main()[3])/len(main()[3])\n",
    "\n",
    "    ### Print the accuracy of the Logistic Regressor\n",
    "    print(\"Accuracy of LR on the test dataset is {}.\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic loss after 1 iterations is 0.6838623451102486\n",
      "Logistic loss after 10001 iterations is 0.5100447489191648\n",
      "Logistic loss after 20001 iterations is 0.4983314558736882\n",
      "Logistic loss after 30001 iterations is 0.49234880920929286\n",
      "Logistic loss after 40001 iterations is 0.4887060952482046\n",
      "Logistic loss after 50001 iterations is 0.486286212261899\n",
      "Logistic loss after 60001 iterations is 0.4845822765472486\n",
      "Logistic loss after 70001 iterations is 0.4833318116095802\n",
      "Logistic loss after 80001 iterations is 0.48238539816737697\n",
      "Logistic loss after 90001 iterations is 0.4816515366397042\n",
      "Logistic loss after 100001 iterations is 0.4810710338000639\n",
      "Logistic loss after 110001 iterations is 0.480604000307967\n",
      "Logistic loss after 120001 iterations is 0.48022271235549585\n",
      "Logistic loss after 130001 iterations is 0.4799074270946048\n",
      "Logistic loss after 140001 iterations is 0.47964379847079036\n",
      "Logistic loss after 150001 iterations is 0.47942121640871654\n",
      "Logistic loss after 160001 iterations is 0.47923170667140697\n",
      "Logistic loss after 170001 iterations is 0.4790691850274833\n",
      "Logistic loss after 180001 iterations is 0.4789289422516009\n",
      "Logistic loss after 190001 iterations is 0.47880728306921827\n",
      "Converged after 199266 iterations\n",
      "Logistic loss after 199266 iterations is 0.4787085834877322\n",
      "[[ 0.55932521 -0.29250733 20.39407408 -6.46811202 -9.58689304 -2.42987497\n",
      "  -0.27800249  0.29380889  0.57288019 -0.20387819 -0.09552568 -0.59838907\n",
      "   0.57878095 -1.68544601  1.68000317  0.5518428   0.07826584 -0.25764818\n",
      "  -0.21851311  1.17972891]]\n",
      "The weight w of LR is \n",
      " [ 0.55932521 -0.29250733 20.39407408 -6.46811202 -9.58689304 -2.42987497\n",
      " -0.27800249  0.29380889  0.57288019 -0.20387819 -0.09552568 -0.59838907\n",
      "  0.57878095 -1.68544601  1.68000317  0.5518428   0.07826584 -0.25764818\n",
      " -0.21851311].\n",
      "The bias b of LR is 1.179728910345417.\n",
      "Accuracy of LR on the test dataset is 0.7657894736842106.\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I runned my model and obtained a 0.77% accuracy. Not bad for having selected random hyper-paramenters, but maybe with a better understanding of my dataset, some data-cleaning, and sklearn tool-kit can make the difference.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qual_assess</th>\n",
       "      <th>pre_screen</th>\n",
       "      <th>MA_detection_.5</th>\n",
       "      <th>MA_detection_.6</th>\n",
       "      <th>MA_detection_.7</th>\n",
       "      <th>MA_detection_.8</th>\n",
       "      <th>MA_detection_.9</th>\n",
       "      <th>MA_detection_1.0</th>\n",
       "      <th>exudate_detection_.3</th>\n",
       "      <th>exudate_detection_.4</th>\n",
       "      <th>exudate_detection_.5</th>\n",
       "      <th>exudate_detection_.6</th>\n",
       "      <th>exudate_detection_.7</th>\n",
       "      <th>exudate_detection_.8</th>\n",
       "      <th>exudate_detection_.9</th>\n",
       "      <th>exudate_detection_1.0</th>\n",
       "      <th>euc_dist</th>\n",
       "      <th>diam_opt_disc</th>\n",
       "      <th>AM/FM</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>49.895756</td>\n",
       "      <td>17.775994</td>\n",
       "      <td>5.270920</td>\n",
       "      <td>0.771761</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.486903</td>\n",
       "      <td>0.100025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>57.709936</td>\n",
       "      <td>23.799994</td>\n",
       "      <td>3.325423</td>\n",
       "      <td>0.234185</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>55.831441</td>\n",
       "      <td>27.993933</td>\n",
       "      <td>12.687485</td>\n",
       "      <td>4.852282</td>\n",
       "      <td>1.393889</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.530904</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qual_assess  pre_screen  MA_detection_.5  MA_detection_.6  MA_detection_.7  \\\n",
       "0          1.0         1.0             22.0             22.0             22.0   \n",
       "1          1.0         1.0             24.0             24.0             22.0   \n",
       "2          1.0         1.0             62.0             60.0             59.0   \n",
       "\n",
       "   MA_detection_.8  MA_detection_.9  MA_detection_1.0  exudate_detection_.3  \\\n",
       "0             19.0             18.0              14.0             49.895756   \n",
       "1             18.0             16.0              13.0             57.709936   \n",
       "2             54.0             47.0              33.0             55.831441   \n",
       "\n",
       "   exudate_detection_.4  exudate_detection_.5  exudate_detection_.6  \\\n",
       "0             17.775994              5.270920              0.771761   \n",
       "1             23.799994              3.325423              0.234185   \n",
       "2             27.993933             12.687485              4.852282   \n",
       "\n",
       "   exudate_detection_.7  exudate_detection_.8  exudate_detection_.9  \\\n",
       "0              0.018632              0.006864              0.003923   \n",
       "1              0.003903              0.003903              0.003903   \n",
       "2              1.393889              0.373252              0.041817   \n",
       "\n",
       "   exudate_detection_1.0  euc_dist  diam_opt_disc  AM/FM class_label  \n",
       "0               0.003923  0.486903       0.100025    1.0        b'0'  \n",
       "1               0.003903  0.520908       0.144414    0.0        b'0'  \n",
       "2               0.007744  0.530904       0.128548    0.0        b'1'  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I am loading the full dataset and renaming the columns to keep better track of each attribute\n",
    "data_dir = \"..\\..\\..\\data\\data_classification\"\n",
    "data_path = os.path.join(data_dir, \"messidor_classification.csv\")\n",
    "df = pd.read_csv(data_path, header=0)\n",
    "col_names = ['qual_assess','pre_screen','MA_detection_.5','MA_detection_.6','MA_detection_.7','MA_detection_.8',\n",
    "             'MA_detection_.9','MA_detection_1.0','exudate_detection_.3','exudate_detection_.4','exudate_detection_.5','exudate_detection_.6'\n",
    "             ,'exudate_detection_.7','exudate_detection_.8','exudate_detection_.9','exudate_detection_1.0',\n",
    "             'euc_dist','diam_opt_disc','AM/FM','class_label']\n",
    "df.columns = col_names\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I extract binary class in numeric form (1 or 0) from string.\n",
    "df.class_label = df.class_label.apply(lambda x: pd.to_numeric(str(x)[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qual_assess</th>\n",
       "      <th>pre_screen</th>\n",
       "      <th>MA_detection_.5</th>\n",
       "      <th>MA_detection_.6</th>\n",
       "      <th>MA_detection_.7</th>\n",
       "      <th>MA_detection_.8</th>\n",
       "      <th>MA_detection_.9</th>\n",
       "      <th>MA_detection_1.0</th>\n",
       "      <th>exudate_detection_.3</th>\n",
       "      <th>exudate_detection_.4</th>\n",
       "      <th>exudate_detection_.5</th>\n",
       "      <th>exudate_detection_.6</th>\n",
       "      <th>exudate_detection_.7</th>\n",
       "      <th>exudate_detection_.8</th>\n",
       "      <th>exudate_detection_.9</th>\n",
       "      <th>exudate_detection_1.0</th>\n",
       "      <th>euc_dist</th>\n",
       "      <th>diam_opt_disc</th>\n",
       "      <th>AM/FM</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qual_assess</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017611</td>\n",
       "      <td>0.035576</td>\n",
       "      <td>0.035929</td>\n",
       "      <td>0.033395</td>\n",
       "      <td>0.036506</td>\n",
       "      <td>0.034817</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>0.063597</td>\n",
       "      <td>0.063061</td>\n",
       "      <td>0.044449</td>\n",
       "      <td>0.027656</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>-0.021943</td>\n",
       "      <td>-0.067325</td>\n",
       "      <td>-0.051723</td>\n",
       "      <td>0.062816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_screen</th>\n",
       "      <td>-0.017611</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.054839</td>\n",
       "      <td>0.053056</td>\n",
       "      <td>0.059063</td>\n",
       "      <td>0.060557</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.062930</td>\n",
       "      <td>0.052453</td>\n",
       "      <td>0.053534</td>\n",
       "      <td>0.041607</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.023268</td>\n",
       "      <td>0.023861</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>-0.079577</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>-0.076925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA_detection_.5</th>\n",
       "      <td>0.035576</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996177</td>\n",
       "      <td>0.985730</td>\n",
       "      <td>0.963149</td>\n",
       "      <td>0.925274</td>\n",
       "      <td>0.859620</td>\n",
       "      <td>-0.229653</td>\n",
       "      <td>-0.103047</td>\n",
       "      <td>-0.044650</td>\n",
       "      <td>0.103035</td>\n",
       "      <td>0.134464</td>\n",
       "      <td>0.142917</td>\n",
       "      <td>0.196550</td>\n",
       "      <td>0.208422</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.033992</td>\n",
       "      <td>-0.344317</td>\n",
       "      <td>0.292603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA_detection_.6</th>\n",
       "      <td>0.035929</td>\n",
       "      <td>0.054839</td>\n",
       "      <td>0.996177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994221</td>\n",
       "      <td>0.977030</td>\n",
       "      <td>0.944504</td>\n",
       "      <td>0.883511</td>\n",
       "      <td>-0.244704</td>\n",
       "      <td>-0.115253</td>\n",
       "      <td>-0.058364</td>\n",
       "      <td>0.086486</td>\n",
       "      <td>0.117895</td>\n",
       "      <td>0.124198</td>\n",
       "      <td>0.172633</td>\n",
       "      <td>0.185645</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>-0.360716</td>\n",
       "      <td>0.266338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA_detection_.7</th>\n",
       "      <td>0.033395</td>\n",
       "      <td>0.053056</td>\n",
       "      <td>0.985730</td>\n",
       "      <td>0.994221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991821</td>\n",
       "      <td>0.968676</td>\n",
       "      <td>0.916198</td>\n",
       "      <td>-0.283188</td>\n",
       "      <td>-0.139111</td>\n",
       "      <td>-0.086595</td>\n",
       "      <td>0.057769</td>\n",
       "      <td>0.094513</td>\n",
       "      <td>0.098859</td>\n",
       "      <td>0.140774</td>\n",
       "      <td>0.156441</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.030396</td>\n",
       "      <td>-0.389384</td>\n",
       "      <td>0.234691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA_detection_.8</th>\n",
       "      <td>0.036506</td>\n",
       "      <td>0.059063</td>\n",
       "      <td>0.963149</td>\n",
       "      <td>0.977030</td>\n",
       "      <td>0.991821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988294</td>\n",
       "      <td>0.947860</td>\n",
       "      <td>-0.309950</td>\n",
       "      <td>-0.160011</td>\n",
       "      <td>-0.109946</td>\n",
       "      <td>0.029768</td>\n",
       "      <td>0.067477</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>0.102638</td>\n",
       "      <td>0.119405</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>-0.411806</td>\n",
       "      <td>0.197511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA_detection_.9</th>\n",
       "      <td>0.034817</td>\n",
       "      <td>0.060557</td>\n",
       "      <td>0.925274</td>\n",
       "      <td>0.944504</td>\n",
       "      <td>0.968676</td>\n",
       "      <td>0.988294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.974577</td>\n",
       "      <td>-0.349811</td>\n",
       "      <td>-0.197279</td>\n",
       "      <td>-0.152578</td>\n",
       "      <td>-0.020469</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>0.024959</td>\n",
       "      <td>0.050579</td>\n",
       "      <td>0.070735</td>\n",
       "      <td>-0.001725</td>\n",
       "      <td>0.010961</td>\n",
       "      <td>-0.437036</td>\n",
       "      <td>0.161631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MA_detection_1.0</th>\n",
       "      <td>0.031889</td>\n",
       "      <td>0.060152</td>\n",
       "      <td>0.859620</td>\n",
       "      <td>0.883511</td>\n",
       "      <td>0.916198</td>\n",
       "      <td>0.947860</td>\n",
       "      <td>0.974577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.375506</td>\n",
       "      <td>-0.223681</td>\n",
       "      <td>-0.181197</td>\n",
       "      <td>-0.058153</td>\n",
       "      <td>-0.012400</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.031520</td>\n",
       "      <td>-0.002557</td>\n",
       "      <td>-0.011607</td>\n",
       "      <td>-0.435127</td>\n",
       "      <td>0.127861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exudate_detection_.3</th>\n",
       "      <td>0.063597</td>\n",
       "      <td>0.062930</td>\n",
       "      <td>-0.229653</td>\n",
       "      <td>-0.244704</td>\n",
       "      <td>-0.283188</td>\n",
       "      <td>-0.309950</td>\n",
       "      <td>-0.349811</td>\n",
       "      <td>-0.375506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.767091</td>\n",
       "      <td>0.763409</td>\n",
       "      <td>0.486606</td>\n",
       "      <td>0.163915</td>\n",
       "      <td>0.132227</td>\n",
       "      <td>0.114722</td>\n",
       "      <td>0.084682</td>\n",
       "      <td>-0.086155</td>\n",
       "      <td>-0.086474</td>\n",
       "      <td>0.390304</td>\n",
       "      <td>0.058015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exudate_detection_.4</th>\n",
       "      <td>0.063061</td>\n",
       "      <td>0.052453</td>\n",
       "      <td>-0.103047</td>\n",
       "      <td>-0.115253</td>\n",
       "      <td>-0.139111</td>\n",
       "      <td>-0.160011</td>\n",
       "      <td>-0.197279</td>\n",
       "      <td>-0.223681</td>\n",
       "      <td>0.767091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919589</td>\n",
       "      <td>0.624537</td>\n",
       "      <td>0.257159</td>\n",
       "      <td>0.216127</td>\n",
       "      <td>0.181431</td>\n",
       "      <td>0.139196</td>\n",
       "      <td>-0.128990</td>\n",
       "      <td>-0.090721</td>\n",
       "      <td>0.291554</td>\n",
       "      <td>0.000479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exudate_detection_.5</th>\n",
       "      <td>0.044449</td>\n",
       "      <td>0.053534</td>\n",
       "      <td>-0.044650</td>\n",
       "      <td>-0.058364</td>\n",
       "      <td>-0.086595</td>\n",
       "      <td>-0.109946</td>\n",
       "      <td>-0.152578</td>\n",
       "      <td>-0.181197</td>\n",
       "      <td>0.763409</td>\n",
       "      <td>0.919589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780891</td>\n",
       "      <td>0.383977</td>\n",
       "      <td>0.328839</td>\n",
       "      <td>0.273616</td>\n",
       "      <td>0.214250</td>\n",
       "      <td>-0.128006</td>\n",
       "      <td>-0.098866</td>\n",
       "      <td>0.284990</td>\n",
       "      <td>0.038281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exudate_detection_.6</th>\n",
       "      <td>0.027656</td>\n",
       "      <td>0.041607</td>\n",
       "      <td>0.103035</td>\n",
       "      <td>0.086486</td>\n",
       "      <td>0.057769</td>\n",
       "      <td>0.029768</td>\n",
       "      <td>-0.020469</td>\n",
       "      <td>-0.058153</td>\n",
       "      <td>0.486606</td>\n",
       "      <td>0.624537</td>\n",
       "      <td>0.780891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.825772</td>\n",
       "      <td>0.758195</td>\n",
       "      <td>0.636787</td>\n",
       "      <td>0.518501</td>\n",
       "      <td>-0.167954</td>\n",
       "      <td>-0.090738</td>\n",
       "      <td>0.172499</td>\n",
       "      <td>0.104254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exudate_detection_.7</th>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.134464</td>\n",
       "      <td>0.117895</td>\n",
       "      <td>0.094513</td>\n",
       "      <td>0.067477</td>\n",
       "      <td>0.022265</td>\n",
       "      <td>-0.012400</td>\n",
       "      <td>0.163915</td>\n",
       "      <td>0.257159</td>\n",
       "      <td>0.383977</td>\n",
       "      <td>0.825772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931661</td>\n",
       "      <td>0.772151</td>\n",
       "      <td>0.625245</td>\n",
       "      <td>-0.149553</td>\n",
       "      <td>-0.058645</td>\n",
       "      <td>0.072363</td>\n",
       "      <td>0.142273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exudate_detection_.8</th>\n",
       "      <td>0.011864</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.142917</td>\n",
       "      <td>0.124198</td>\n",
       "      <td>0.098859</td>\n",
       "      <td>0.069797</td>\n",
       "      <td>0.024959</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>0.132227</td>\n",
       "      <td>0.216127</td>\n",
       "      <td>0.328839</td>\n",
       "      <td>0.758195</td>\n",
       "      <td>0.931661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906374</td>\n",
       "      <td>0.782185</td>\n",
       "      <td>-0.150996</td>\n",
       "      <td>-0.060441</td>\n",
       "      <td>0.053580</td>\n",
       "      <td>0.151424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exudate_detection_.9</th>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.023268</td>\n",
       "      <td>0.196550</td>\n",
       "      <td>0.172633</td>\n",
       "      <td>0.140774</td>\n",
       "      <td>0.102638</td>\n",
       "      <td>0.050579</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.114722</td>\n",
       "      <td>0.181431</td>\n",
       "      <td>0.273616</td>\n",
       "      <td>0.636787</td>\n",
       "      <td>0.772151</td>\n",
       "      <td>0.906374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943460</td>\n",
       "      <td>-0.122688</td>\n",
       "      <td>-0.039783</td>\n",
       "      <td>0.040861</td>\n",
       "      <td>0.184772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exudate_detection_1.0</th>\n",
       "      <td>0.012289</td>\n",
       "      <td>0.023861</td>\n",
       "      <td>0.208422</td>\n",
       "      <td>0.185645</td>\n",
       "      <td>0.156441</td>\n",
       "      <td>0.119405</td>\n",
       "      <td>0.070735</td>\n",
       "      <td>0.031520</td>\n",
       "      <td>0.084682</td>\n",
       "      <td>0.139196</td>\n",
       "      <td>0.214250</td>\n",
       "      <td>0.518501</td>\n",
       "      <td>0.625245</td>\n",
       "      <td>0.782185</td>\n",
       "      <td>0.943460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.097073</td>\n",
       "      <td>-0.019091</td>\n",
       "      <td>0.028232</td>\n",
       "      <td>0.177313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euc_dist</th>\n",
       "      <td>-0.021943</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>-0.001725</td>\n",
       "      <td>-0.002557</td>\n",
       "      <td>-0.086155</td>\n",
       "      <td>-0.128990</td>\n",
       "      <td>-0.128006</td>\n",
       "      <td>-0.167954</td>\n",
       "      <td>-0.149553</td>\n",
       "      <td>-0.150996</td>\n",
       "      <td>-0.122688</td>\n",
       "      <td>-0.097073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131497</td>\n",
       "      <td>-0.009871</td>\n",
       "      <td>0.008466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diam_opt_disc</th>\n",
       "      <td>-0.067325</td>\n",
       "      <td>-0.079577</td>\n",
       "      <td>0.033992</td>\n",
       "      <td>0.034714</td>\n",
       "      <td>0.030396</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.010961</td>\n",
       "      <td>-0.011607</td>\n",
       "      <td>-0.086474</td>\n",
       "      <td>-0.090721</td>\n",
       "      <td>-0.098866</td>\n",
       "      <td>-0.090738</td>\n",
       "      <td>-0.058645</td>\n",
       "      <td>-0.060441</td>\n",
       "      <td>-0.039783</td>\n",
       "      <td>-0.019091</td>\n",
       "      <td>-0.131497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082398</td>\n",
       "      <td>-0.030868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AM/FM</th>\n",
       "      <td>-0.051723</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>-0.344317</td>\n",
       "      <td>-0.360716</td>\n",
       "      <td>-0.389384</td>\n",
       "      <td>-0.411806</td>\n",
       "      <td>-0.437036</td>\n",
       "      <td>-0.435127</td>\n",
       "      <td>0.390304</td>\n",
       "      <td>0.291554</td>\n",
       "      <td>0.284990</td>\n",
       "      <td>0.172499</td>\n",
       "      <td>0.072363</td>\n",
       "      <td>0.053580</td>\n",
       "      <td>0.040861</td>\n",
       "      <td>0.028232</td>\n",
       "      <td>-0.009871</td>\n",
       "      <td>-0.082398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_label</th>\n",
       "      <td>0.062816</td>\n",
       "      <td>-0.076925</td>\n",
       "      <td>0.292603</td>\n",
       "      <td>0.266338</td>\n",
       "      <td>0.234691</td>\n",
       "      <td>0.197511</td>\n",
       "      <td>0.161631</td>\n",
       "      <td>0.127861</td>\n",
       "      <td>0.058015</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.038281</td>\n",
       "      <td>0.104254</td>\n",
       "      <td>0.142273</td>\n",
       "      <td>0.151424</td>\n",
       "      <td>0.184772</td>\n",
       "      <td>0.177313</td>\n",
       "      <td>0.008466</td>\n",
       "      <td>-0.030868</td>\n",
       "      <td>-0.042144</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       qual_assess  pre_screen  MA_detection_.5  \\\n",
       "qual_assess               1.000000   -0.017611         0.035576   \n",
       "pre_screen               -0.017611    1.000000         0.053300   \n",
       "MA_detection_.5           0.035576    0.053300         1.000000   \n",
       "MA_detection_.6           0.035929    0.054839         0.996177   \n",
       "MA_detection_.7           0.033395    0.053056         0.985730   \n",
       "MA_detection_.8           0.036506    0.059063         0.963149   \n",
       "MA_detection_.9           0.034817    0.060557         0.925274   \n",
       "MA_detection_1.0          0.031889    0.060152         0.859620   \n",
       "exudate_detection_.3      0.063597    0.062930        -0.229653   \n",
       "exudate_detection_.4      0.063061    0.052453        -0.103047   \n",
       "exudate_detection_.5      0.044449    0.053534        -0.044650   \n",
       "exudate_detection_.6      0.027656    0.041607         0.103035   \n",
       "exudate_detection_.7      0.013336    0.015900         0.134464   \n",
       "exudate_detection_.8      0.011864    0.018950         0.142917   \n",
       "exudate_detection_.9      0.012695    0.023268         0.196550   \n",
       "exudate_detection_1.0     0.012289    0.023861         0.208422   \n",
       "euc_dist                 -0.021943    0.004751         0.000001   \n",
       "diam_opt_disc            -0.067325   -0.079577         0.033992   \n",
       "AM/FM                    -0.051723    0.010782        -0.344317   \n",
       "class_label               0.062816   -0.076925         0.292603   \n",
       "\n",
       "                       MA_detection_.6  MA_detection_.7  MA_detection_.8  \\\n",
       "qual_assess                   0.035929         0.033395         0.036506   \n",
       "pre_screen                    0.054839         0.053056         0.059063   \n",
       "MA_detection_.5               0.996177         0.985730         0.963149   \n",
       "MA_detection_.6               1.000000         0.994221         0.977030   \n",
       "MA_detection_.7               0.994221         1.000000         0.991821   \n",
       "MA_detection_.8               0.977030         0.991821         1.000000   \n",
       "MA_detection_.9               0.944504         0.968676         0.988294   \n",
       "MA_detection_1.0              0.883511         0.916198         0.947860   \n",
       "exudate_detection_.3         -0.244704        -0.283188        -0.309950   \n",
       "exudate_detection_.4         -0.115253        -0.139111        -0.160011   \n",
       "exudate_detection_.5         -0.058364        -0.086595        -0.109946   \n",
       "exudate_detection_.6          0.086486         0.057769         0.029768   \n",
       "exudate_detection_.7          0.117895         0.094513         0.067477   \n",
       "exudate_detection_.8          0.124198         0.098859         0.069797   \n",
       "exudate_detection_.9          0.172633         0.140774         0.102638   \n",
       "exudate_detection_1.0         0.185645         0.156441         0.119405   \n",
       "euc_dist                      0.001953         0.000387         0.001520   \n",
       "diam_opt_disc                 0.034714         0.030396         0.016854   \n",
       "AM/FM                        -0.360716        -0.389384        -0.411806   \n",
       "class_label                   0.266338         0.234691         0.197511   \n",
       "\n",
       "                       MA_detection_.9  MA_detection_1.0  \\\n",
       "qual_assess                   0.034817          0.031889   \n",
       "pre_screen                    0.060557          0.060152   \n",
       "MA_detection_.5               0.925274          0.859620   \n",
       "MA_detection_.6               0.944504          0.883511   \n",
       "MA_detection_.7               0.968676          0.916198   \n",
       "MA_detection_.8               0.988294          0.947860   \n",
       "MA_detection_.9               1.000000          0.974577   \n",
       "MA_detection_1.0              0.974577          1.000000   \n",
       "exudate_detection_.3         -0.349811         -0.375506   \n",
       "exudate_detection_.4         -0.197279         -0.223681   \n",
       "exudate_detection_.5         -0.152578         -0.181197   \n",
       "exudate_detection_.6         -0.020469         -0.058153   \n",
       "exudate_detection_.7          0.022265         -0.012400   \n",
       "exudate_detection_.8          0.024959         -0.012175   \n",
       "exudate_detection_.9          0.050579          0.006868   \n",
       "exudate_detection_1.0         0.070735          0.031520   \n",
       "euc_dist                     -0.001725         -0.002557   \n",
       "diam_opt_disc                 0.010961         -0.011607   \n",
       "AM/FM                        -0.437036         -0.435127   \n",
       "class_label                   0.161631          0.127861   \n",
       "\n",
       "                       exudate_detection_.3  exudate_detection_.4  \\\n",
       "qual_assess                        0.063597              0.063061   \n",
       "pre_screen                         0.062930              0.052453   \n",
       "MA_detection_.5                   -0.229653             -0.103047   \n",
       "MA_detection_.6                   -0.244704             -0.115253   \n",
       "MA_detection_.7                   -0.283188             -0.139111   \n",
       "MA_detection_.8                   -0.309950             -0.160011   \n",
       "MA_detection_.9                   -0.349811             -0.197279   \n",
       "MA_detection_1.0                  -0.375506             -0.223681   \n",
       "exudate_detection_.3               1.000000              0.767091   \n",
       "exudate_detection_.4               0.767091              1.000000   \n",
       "exudate_detection_.5               0.763409              0.919589   \n",
       "exudate_detection_.6               0.486606              0.624537   \n",
       "exudate_detection_.7               0.163915              0.257159   \n",
       "exudate_detection_.8               0.132227              0.216127   \n",
       "exudate_detection_.9               0.114722              0.181431   \n",
       "exudate_detection_1.0              0.084682              0.139196   \n",
       "euc_dist                          -0.086155             -0.128990   \n",
       "diam_opt_disc                     -0.086474             -0.090721   \n",
       "AM/FM                              0.390304              0.291554   \n",
       "class_label                        0.058015              0.000479   \n",
       "\n",
       "                       exudate_detection_.5  exudate_detection_.6  \\\n",
       "qual_assess                        0.044449              0.027656   \n",
       "pre_screen                         0.053534              0.041607   \n",
       "MA_detection_.5                   -0.044650              0.103035   \n",
       "MA_detection_.6                   -0.058364              0.086486   \n",
       "MA_detection_.7                   -0.086595              0.057769   \n",
       "MA_detection_.8                   -0.109946              0.029768   \n",
       "MA_detection_.9                   -0.152578             -0.020469   \n",
       "MA_detection_1.0                  -0.181197             -0.058153   \n",
       "exudate_detection_.3               0.763409              0.486606   \n",
       "exudate_detection_.4               0.919589              0.624537   \n",
       "exudate_detection_.5               1.000000              0.780891   \n",
       "exudate_detection_.6               0.780891              1.000000   \n",
       "exudate_detection_.7               0.383977              0.825772   \n",
       "exudate_detection_.8               0.328839              0.758195   \n",
       "exudate_detection_.9               0.273616              0.636787   \n",
       "exudate_detection_1.0              0.214250              0.518501   \n",
       "euc_dist                          -0.128006             -0.167954   \n",
       "diam_opt_disc                     -0.098866             -0.090738   \n",
       "AM/FM                              0.284990              0.172499   \n",
       "class_label                        0.038281              0.104254   \n",
       "\n",
       "                       exudate_detection_.7  exudate_detection_.8  \\\n",
       "qual_assess                        0.013336              0.011864   \n",
       "pre_screen                         0.015900              0.018950   \n",
       "MA_detection_.5                    0.134464              0.142917   \n",
       "MA_detection_.6                    0.117895              0.124198   \n",
       "MA_detection_.7                    0.094513              0.098859   \n",
       "MA_detection_.8                    0.067477              0.069797   \n",
       "MA_detection_.9                    0.022265              0.024959   \n",
       "MA_detection_1.0                  -0.012400             -0.012175   \n",
       "exudate_detection_.3               0.163915              0.132227   \n",
       "exudate_detection_.4               0.257159              0.216127   \n",
       "exudate_detection_.5               0.383977              0.328839   \n",
       "exudate_detection_.6               0.825772              0.758195   \n",
       "exudate_detection_.7               1.000000              0.931661   \n",
       "exudate_detection_.8               0.931661              1.000000   \n",
       "exudate_detection_.9               0.772151              0.906374   \n",
       "exudate_detection_1.0              0.625245              0.782185   \n",
       "euc_dist                          -0.149553             -0.150996   \n",
       "diam_opt_disc                     -0.058645             -0.060441   \n",
       "AM/FM                              0.072363              0.053580   \n",
       "class_label                        0.142273              0.151424   \n",
       "\n",
       "                       exudate_detection_.9  exudate_detection_1.0  euc_dist  \\\n",
       "qual_assess                        0.012695               0.012289 -0.021943   \n",
       "pre_screen                         0.023268               0.023861  0.004751   \n",
       "MA_detection_.5                    0.196550               0.208422  0.000001   \n",
       "MA_detection_.6                    0.172633               0.185645  0.001953   \n",
       "MA_detection_.7                    0.140774               0.156441  0.000387   \n",
       "MA_detection_.8                    0.102638               0.119405  0.001520   \n",
       "MA_detection_.9                    0.050579               0.070735 -0.001725   \n",
       "MA_detection_1.0                   0.006868               0.031520 -0.002557   \n",
       "exudate_detection_.3               0.114722               0.084682 -0.086155   \n",
       "exudate_detection_.4               0.181431               0.139196 -0.128990   \n",
       "exudate_detection_.5               0.273616               0.214250 -0.128006   \n",
       "exudate_detection_.6               0.636787               0.518501 -0.167954   \n",
       "exudate_detection_.7               0.772151               0.625245 -0.149553   \n",
       "exudate_detection_.8               0.906374               0.782185 -0.150996   \n",
       "exudate_detection_.9               1.000000               0.943460 -0.122688   \n",
       "exudate_detection_1.0              0.943460               1.000000 -0.097073   \n",
       "euc_dist                          -0.122688              -0.097073  1.000000   \n",
       "diam_opt_disc                     -0.039783              -0.019091 -0.131497   \n",
       "AM/FM                              0.040861               0.028232 -0.009871   \n",
       "class_label                        0.184772               0.177313  0.008466   \n",
       "\n",
       "                       diam_opt_disc     AM/FM  class_label  \n",
       "qual_assess                -0.067325 -0.051723     0.062816  \n",
       "pre_screen                 -0.079577  0.010782    -0.076925  \n",
       "MA_detection_.5             0.033992 -0.344317     0.292603  \n",
       "MA_detection_.6             0.034714 -0.360716     0.266338  \n",
       "MA_detection_.7             0.030396 -0.389384     0.234691  \n",
       "MA_detection_.8             0.016854 -0.411806     0.197511  \n",
       "MA_detection_.9             0.010961 -0.437036     0.161631  \n",
       "MA_detection_1.0           -0.011607 -0.435127     0.127861  \n",
       "exudate_detection_.3       -0.086474  0.390304     0.058015  \n",
       "exudate_detection_.4       -0.090721  0.291554     0.000479  \n",
       "exudate_detection_.5       -0.098866  0.284990     0.038281  \n",
       "exudate_detection_.6       -0.090738  0.172499     0.104254  \n",
       "exudate_detection_.7       -0.058645  0.072363     0.142273  \n",
       "exudate_detection_.8       -0.060441  0.053580     0.151424  \n",
       "exudate_detection_.9       -0.039783  0.040861     0.184772  \n",
       "exudate_detection_1.0      -0.019091  0.028232     0.177313  \n",
       "euc_dist                   -0.131497 -0.009871     0.008466  \n",
       "diam_opt_disc               1.000000 -0.082398    -0.030868  \n",
       "AM/FM                      -0.082398  1.000000    -0.042144  \n",
       "class_label                -0.030868 -0.042144     1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for high correlation among features\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Heatmap of correlation above 0.8.\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "sns.heatmap(abs(df.corr()) > .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation heatmaps give me a visual understanding of the importance of the dataset attributes. Here, I can see that there is a high correlation with all MA_detection attributes and therefore, I could choouse only one along them to continue.  \n",
    "\n",
    "I could search for the best MA featuresby running 6 different datasets, each keeping a different MA feature. Yet I am just going to assume MA5 works best and move along. To do so, I specify the MA columns I want to drop, all but MA5. I also drop every other exudate\n",
    "detection column for all datasets. This will eliminate correlation among exudate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MA5 = df.copy()\n",
    "drop_5 = ['MA_detection_1.0','MA_detection_.6','MA_detection_.7','MA_detection_.8',\n",
    "             'MA_detection_.9', 'exudate_detection_.4','exudate_detection_.6','exudate_detection_.8',\n",
    "                  'exudate_detection_1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['qual_assess', 'pre_screen', 'MA_detection_.5', 'exudate_detection_.3',\n",
      "       'exudate_detection_.5', 'exudate_detection_.7', 'exudate_detection_.9',\n",
      "       'euc_dist', 'diam_opt_disc', 'AM/FM', 'class_label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop appropriate columns to create these dataframes.\n",
    "df_MA5.drop(columns = drop_5, inplace = True)\n",
    "\n",
    "# Check to make sure the desired result is achieved. \n",
    "print(df_MA5.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the correlation of MA5 dataframe. \n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "sns.heatmap(abs(df_MA5.corr()) > .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve our performance, we want to make sure that the data we are dealing with is good. This means, there is no missing data, we are aware of the data types, and we fix possible mistakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets function\n",
    "def load_data(data_file_name):\n",
    "    data_dir = \"..\\..\\..\\data\\data_classification\"\n",
    "    data_path = os.path.join(data_dir, data_file_name)\n",
    "    df = pd.read_csv(data_path, header=1)\n",
    "    data_X = df.iloc[:,:-1]\n",
    "    data_y = df.iloc[:,-1]\n",
    "    scaler_X = StandardScaler()\n",
    "    data_X = scaler_X.fit_transform(data_X)\n",
    "    data_y = pd.Categorical(data_y).codes.reshape(-1)\n",
    "    return data_X, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # read dataset from csv file\n",
    "    data_name = \"messidor_classification\"\n",
    "    data_X, data_y = load_data(\"{}.csv\".format(data_name))\n",
    "    data_y = np.where(data_y==0,-1,data_y)\n",
    "\n",
    "    return data_X, data_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "x, y = main()\n",
    "dfx = pd.DataFrame(x) \n",
    "dfy = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_label\n",
       "0           -1\n",
       "1            1\n",
       "2           -1\n",
       "3            1\n",
       "4            1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfx.dtypes\n",
    "col_names = ['qual_assess','pre_screen','MA_detection_.5','MA_detection_.6','MA_detection_.7','MA_detection_.8',\n",
    "             'MA_detection_.9','MA_detection_1.0','exudate_detection_.3','exudate_detection_.4','exudate_detection_.5','exudate_detection_.6'\n",
    "             ,'exudate_detection_.7','exudate_detection_.8','exudate_detection_.9','exudate_detection_1.0',\n",
    "             'euc_dist','diam_opt_disc','AM/FM']\n",
    "dfx.columns = col_names\n",
    "\n",
    "dfy.rename({0:'class_label'}, axis='columns', inplace=True) \n",
    "dfy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the Gaussian kernel (RBF kernel) for SVM. For any $x_i, x_j \\in\\mathbb{R}^d$, we define\n",
    "$$\n",
    "\\kappa(x_i, x_j) = \\exp \\bigl( - \\|x_i - x_j\\|^2 / (2 \\sigma^2) \\bigr)\n",
    "$$ \n",
    "where $\\sigma > 0$ is the width of the Gaussian kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    '''\n",
    "    This is a class for support vector machine.\n",
    "    \n",
    "    The class contains the hyper-parameters such as $C$ and the kernel bandwidth $\\sigma$. It also contains \n",
    "    the alpha vector, the tolerance for prediction error and the maximum number of iteration.\n",
    "    \n",
    "    It contains the functions for calculating the kernel matrix, fitting the model to estimate alpha and b \n",
    "    with SMO algorithm, making predictions and other fundamental functions.\n",
    "    \n",
    "    Attributes:\n",
    "        C (positive number)         - the hyperparameter for SVM algorithm\n",
    "        sigma (positive number)     - the kernel bandwidth $\\sigma$ of Gaussian kernel \n",
    "        toler (positive number)     - the threshold value of prediction error. If the prediction error of \n",
    "                                      a sample is larger than this value, the corresponding alpha_i will be \n",
    "                                      probably updated.\n",
    "        maxIter (positive integer)  - the maximum number of iteration to search a pair of alpha's to update\n",
    "        alphas (vector, num_samples)- the alpha vector in the dual problem \n",
    "        b (number)                  - the bias b\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, C = 1, sigma = 1, toler = 0.01, maxIter = 100):\n",
    "        self.C = C\n",
    "        self.sigma = sigma\n",
    "        self.toler = toler\n",
    "        self.maxIter = maxIter\n",
    "        self.alphas = 0\n",
    "        self.b = 0\n",
    "        \n",
    "    def rbfkernel(self, X, Y):\n",
    "        '''\n",
    "        Calculate the kernel matrix whose (i,j)-th entry is $k(X[i,:], Y[j,:])$.\n",
    "        '''\n",
    "        m = X.shape[0]\n",
    "        n = Y.shape[0]\n",
    "        K = np.zeros(shape=(m, n))\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                K[i, j] = np.sum((X[i,:] - Y[j,:])**2)\n",
    "        K = np.exp(-K / (2 * self.sigma**2))\n",
    "        return K\n",
    "\n",
    "    def selectJrand(self, i, m):\n",
    "        '''\n",
    "        Randomly choose an index $j\\neq i$ from 0 to m-1\n",
    "        '''\n",
    "        j = i \n",
    "        while (j == i):\n",
    "            j = int(np.random.uniform(0, m))\n",
    "        return j\n",
    "\n",
    "\n",
    "    def clipAlpha(self, aj, H, L):\n",
    "        '''\n",
    "        Clip the vale aj by the lower bound L and upper bound H\n",
    "        '''\n",
    "        if aj > H:\n",
    "            aj = H\n",
    "        if L > aj:\n",
    "            aj = L\n",
    "        return aj\n",
    "\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        '''\n",
    "        estimate the alphas vector and bias in the SVM model\n",
    "        \n",
    "        Args: \n",
    "            X_train (matrix, num_train*num_features): features of training samples\n",
    "            y_train (vector, num_train): label of training samples, each label is either -1 or 1\n",
    "            \n",
    "        Returns:\n",
    "            self.b (a number)                 : the bias\n",
    "            self.alphas (vector, num_features): the alpha vector \n",
    "        ''' \n",
    "        K_train = self.rbfkernel(X_train, X_train)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        m = K_train.shape[0]\n",
    "        self.alphas = np.zeros((m, ))\n",
    "        num_iter = 0\n",
    "        while (num_iter < self.maxIter):\n",
    "            alphaPairsChanged = 0\n",
    "            # optimize for each data vector (with kernel trick)\n",
    "            for i in range(m):   \n",
    "                fXi = (self.alphas * y_train) @ K_train[i, :] + self.b\n",
    "                # if checks if an example violates KKT conditions\n",
    "                Ei = fXi - y_train[i]\n",
    "                if ((y_train[i] * Ei < -self.toler) and (self.alphas[i] < self.C)) \\\n",
    "                       or ((y_train[i] * Ei > self.toler) and (self.alphas[i] > 0)):\n",
    "                    j = self.selectJrand(i, m)\n",
    "                    fXj = (self.alphas * y_train) @ K_train[j, :] + self.b\n",
    "                    Ej = fXj - y_train[j]\n",
    "                    alphaJold = self.alphas[j].copy()\n",
    "                    alphaIold = self.alphas[i].copy()\n",
    "                    if (y_train[j] != y_train[i]):\n",
    "                        L = max(0, self.alphas[i] - self.alphas[j])\n",
    "                        H = min(self.C, self.C + self.alphas[i] - self.alphas[j])\n",
    "                    else:\n",
    "                        L = max(0, self.alphas[i] + self.alphas[j] - self.C)\n",
    "                        H = min(self.C, self.alphas[i] + self.alphas[j])\n",
    "                    if L == H:\n",
    "                        continue\n",
    "                    eta = 2.0 * K_train[j, i] - K_train[j, j] - K_train[i, i]\n",
    "                    if eta >= 0:\n",
    "                        continue\n",
    "                    self.alphas[i] += y_train[i] * (Ei - Ej) / eta\n",
    "                    self.alphas[i] = self.clipAlpha(self.alphas[i], H, L)\n",
    "                    if (abs(self.alphas[i] - alphaIold) < 0.00001):\n",
    "                        continue\n",
    "                    # update i by the same amount as j, the direction depends on y[i] and y[j]\n",
    "                    self.alphas[j] += y_train[i] * y_train[j] * (alphaIold - self.alphas[i])\n",
    "                    # update self.b\n",
    "                    b1 = self.b - Ej - y_train[j] * (self.alphas[j] - alphaJold) * K_train[\n",
    "                        j, j] - y_train[i] * (self.alphas[i] - alphaIold) * K_train[j, i]\n",
    "                    b2 = self.b - Ei - y_train[j] * (self.alphas[j] - alphaJold) * K_train[\n",
    "                        j, i] - y_train[i] * (self.alphas[i] - alphaIold) * K_train[i, i]\n",
    "                    if (0 < self.alphas[j]) and (self.C > self.alphas[j]): self.b = b1\n",
    "                    elif (0 < self.alphas[i]) and (self.C > self.alphas[i]): self.b = b2\n",
    "                    else: self.b = (b1 + b2) / 2.0\n",
    "                    alphaPairsChanged += 1\n",
    "            if (alphaPairsChanged == 0): num_iter += 1\n",
    "            else: num_iter = 0\n",
    "        return self.b, self.alphas\n",
    "\n",
    "\n",
    "    def predict(self,X_test):\n",
    "        '''\n",
    "        predict the label of test samples\n",
    "        Args:\n",
    "            X_test(matrix, num_test*num_features): features of test samples\n",
    "        Returns:\n",
    "            y_hat(vector, num_test): the predicted label of test samples, each label is either -1 or 1\n",
    "        '''\n",
    "        K_test = self.rbfkernel(self.X_train, X_test)\n",
    "        f = K_test.T @ (self.alphas * self.y_train) + self.b\n",
    "        y_hat = np.sign(f)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SVM on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_t():\n",
    "    # Randomly assingning a train and test set\n",
    "    train_X, test_X, train_y, test_y = train_test_split(main()[0], main()[1], test_size=0.33, random_state=100)\n",
    "    return train_X, test_X, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm = SVC(random_state=42)\n",
    "clf_svm.fit(t_t()[0], t_t()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x254ba13d030>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(clf_svm,t_t()[1],  t_t()[3], values_format='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'C':[0.5, 1, 10, 100], 'gamma': ['scale', 1, 0.1, 0.01, 0.001], 'kernel': ['rbf'] }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "{'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "optimal_params = GridSearchCV(SVC(),\n",
    "                             param_grid,\n",
    "                             cv = 5,\n",
    "                             scoring = 'accuracy' )\n",
    "\n",
    "optimal_params.fit(t_t()[0], t_t()[2])\n",
    "print(optimal_params.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, gamma=0.01, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, gamma=0.01, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, gamma=0.01, random_state=42)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm = SVC(random_state=42, C = 100, gamma=0.01)\n",
    "clf_svm.fit(t_t()[0], t_t()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n",
      "      1.0  1.0.1  22.0  22.0.1  22.0.2  19.0  18.0  14.0  49.895756  \\\n",
      "0     1.0    1.0  24.0    24.0    22.0  18.0  16.0  13.0  57.709936   \n",
      "1     1.0    1.0  62.0    60.0    59.0  54.0  47.0  33.0  55.831441   \n",
      "2     1.0    1.0  55.0    53.0    53.0  50.0  43.0  31.0  40.467228   \n",
      "3     1.0    1.0  44.0    44.0    44.0  41.0  39.0  27.0  18.026254   \n",
      "4     1.0    1.0  44.0    43.0    41.0  41.0  37.0  29.0  28.356400   \n",
      "...   ...    ...   ...     ...     ...   ...   ...   ...        ...   \n",
      "1145  1.0    1.0  34.0    34.0    34.0  33.0  31.0  24.0   6.071765   \n",
      "1146  1.0    1.0  49.0    49.0    49.0  49.0  45.0  37.0  63.197145   \n",
      "1147  1.0    0.0  49.0    48.0    48.0  45.0  43.0  33.0  30.461898   \n",
      "1148  1.0    1.0  39.0    36.0    29.0  23.0  13.0   7.0  40.525739   \n",
      "1149  1.0    1.0   7.0     7.0     7.0   7.0   7.0   5.0  69.423565   \n",
      "\n",
      "      17.775994    5.27092  0.771761  0.018632  0.006864  0.003923  \\\n",
      "0     23.799994   3.325423  0.234185  0.003903  0.003903  0.003903   \n",
      "1     27.993933  12.687485  4.852282  1.393889  0.373252  0.041817   \n",
      "2     18.445954   9.118901  3.079428  0.840261  0.272434  0.007653   \n",
      "3      8.570709   0.410381  0.000000  0.000000  0.000000  0.000000   \n",
      "4      6.935636   2.305771  0.323724  0.000000  0.000000  0.000000   \n",
      "...         ...        ...       ...       ...       ...       ...   \n",
      "1145   0.937472   0.031145  0.003115  0.000000  0.000000  0.000000   \n",
      "1146  27.377668   8.067688  0.979548  0.001552  0.000000  0.000000   \n",
      "1147  13.966980   1.763305  0.137858  0.011221  0.000000  0.000000   \n",
      "1148  12.604947   4.740919  1.077570  0.563518  0.326860  0.239568   \n",
      "1149   7.031843   1.750548  0.046597  0.021180  0.008472  0.000000   \n",
      "\n",
      "      0.003923.1  0.486903  0.100025  1.0.2  b'0'  \n",
      "0       0.003903  0.520908  0.144414    0.0  b'0'  \n",
      "1       0.007744  0.530904  0.128548    0.0  b'1'  \n",
      "2       0.001531  0.483284  0.114790    0.0  b'0'  \n",
      "3       0.000000  0.475935  0.123572    0.0  b'1'  \n",
      "4       0.000000  0.502831  0.126741    0.0  b'1'  \n",
      "...          ...       ...       ...    ...   ...  \n",
      "1145    0.000000  0.537470  0.116795    0.0  b'0'  \n",
      "1146    0.000000  0.516733  0.124190    0.0  b'0'  \n",
      "1147    0.000000  0.560632  0.129843    0.0  b'0'  \n",
      "1148    0.174584  0.485972  0.106690    1.0  b'1'  \n",
      "1149    0.000000  0.556192  0.088957    0.0  b'0'  \n",
      "\n",
      "[1150 rows x 20 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x254f77d5270>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEECAYAAAC8xyi8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAb0UlEQVR4nO3dfVRVdd738ffmUURUMJ8RB3xaOF52mYqa5tSsq4vqnrlaMQXKSNmtNXUXXqgzPiZQLcfSUrvRscH0sjRUTDInm6nGusOysNEUx2RKTQIfSdQEkYdz9v0H4ymnkHOOcB62n1drr8XeZ/PbX1jy7fvbv99vb8M0TRMREQsK8HYAIiKtRQlORCxLCU5ELEsJTkQsSwlORCwryNsB/CvTXgm2Y94Oo3UE9AS79X62L/e19XYIraJr786cKq3wdhitov+wPtf0/WZtIQREOnWuEfxv13Sta2H42jQRs34/5pkkb4fRKoxOBZb82RJ7/Lu3Q2gVy3c9w2MJs7wdRqt4177pmr7frN+P7cw9Tp0b1O3QNV3rWqiLKiIuM02wmXanNmfs27ePtLS0K4796U9/IiUlxbGfn59PUlISycnJvP/++06163NdVBHxByZ2Wqbzt3LlSrZu3UpYWJjj2Oeff85rr73G5Q5mRUUFa9euZfPmzdTW1pKamsro0aMJCQm5atuq4ETEZSZgd/K/5sTExJCTk+PYP3v2LIsXL2bOnDmOY8XFxQwZMoSQkBAiIiKIiYmhpKSk2bZVwYmIy0yg3snuZ2VlJZMnT3bsp6SkXNH1TExMpLy8HACbzcbcuXOZPXs2oaGhjnOqqqqIiIhw7IeHh1NVVdXstZXgRMQNJjYnu6idoqIoKChw6twDBw5QWlpKdnY2tbW1HDp0iPnz5zNy5Eiqq6sd51VXV1+R8JqiBCciLmvsorb8BIzBgwezbds2AMrLy5k2bRpz586loqKCpUuXUltbS11dHYcPH6Z///7NtqcEJyJusXlwhlnnzp1JS0sjNTUV0zSZOnXqFV3YpijBiYjLGiu4lhMdHU1+fv5VjyUnJ5OcnOxSu0pwIuIWZ+/BeZMSnIi4rHEU1dtRNE8JTkRcZgI2DG+H0SwlOBFxi10VnIhYkSo4EbEsJTgRsSzTNKg3fX8puxKciLjF5gfP6lCCExGXmYDdVBdVRCzJ0D04EbEmE7DpHpyIWJVd9+BExIpMDOrMQG+H0SwlOBFxWePTRHQPTkQsydA0ERGxJg0yiIilaZBBRCzJNA1smugrIlbU+MBL308fvh+hiPgcU4MMImJl6qKKiCU1zoNTBScilmRomoiIWFPjIIOWaomIBWmQQUSsy9QDL0XEohpfOqMKTkQsycCuQQYRsSK9NlBELMvE0CiqiFiXuqgiYkl6HpyIWJihR5aLiDWZpio4EbEwf5jo6/spWER8zuVRVGc2Z+zbt4+0tDQADh48SGpqKmlpaUyaNIlvvvkGgPz8fJKSkkhOTub99993ql1VcCLispZ8XNLKlSvZunUrYWFhAMyfP5958+YRHx/Phg0bWLlyJZMnT2bt2rVs3ryZ2tpaUlNTGT16NCEhIVdtWxWciLjF9s/3MjS3VVZWkpSU5Ng2btx4RTsxMTHk5OQ49hcvXkx8fHzjNWw2QkNDKS4uZsiQIYSEhBAREUFMTAwlJSXNxqgKTkRcZmI4fQ8uKiqKgoKCJj9PTEykvLzcsd+lSxcA9uzZw7p163j11VfZsWMHERERjnPCw8Opqqpq9tpKcCLiOrN1J/q+9dZbrFixgtzcXKKiomjXrh3V1dWOz6urq69IeE1RF1VEXNb4wMsApzZXvfHGG6xbt461a9fSq1cvAAYPHszu3bupra3lwoULHD58mP79+zfbliq4Flaypy2r5vdg0eZDjmPvFXRk6/905oWdjfsFuZ35f290BCDh598yYfopL0QqP6ZDp3qWv/0ls8fFERx4nOe3fAmmwdGSNiyb0xPTD6ZGeILZSk8TsdlszJ8/n+7du5Oeng7A8OHDmTJlCmlpaaSmpmKaJlOnTiU0NLTZ9jyS4GpqanjwwQeZP38+ffr08cQlvSJ/eRe2b46kTVu749ih/WG8vaETptm4f6I0hPcKInlh2xcEBMC0u/ty853niRt4yUtRy2WBQSb/vbCc2prGJHZDx1yWPd6d4o/bMeWZckYlfsvOv3TwcpS+oyVXMkRHR5Ofnw/Arl27fvSc5ORkkpOTXWq31buo+/fv59e//jVlZWWtfSmv6/6TWjJf+sqx/21lIP/zTHceefKY41jnHnXMf/UwgYFgGNDQYBASanojXPkXD2UeZ9srnThzKhiA0JBDFH8cDsCn70cwZOwFb4bnUxrXojo3iupNrZ7g6urqWL58OXFxca19Ka+75X+dJ7DxbwObDRZPj+E32ccIa/ddRRcUDB062TBNyH2yB30H1RDdp9ZLEctltydXcv5MELs/aP+9oyb8s0q5WBVAeITNK7H5psYuqjObN7V6F3Xo0KGufUNAT4xOTQ8p+zrjwjkI2syh0ikc/3orOfMGU3epga+/rGDF7z7h0UUF1F1q4PmHtxLWLoT03LswAv17rGf5rrbeDuGa9ez8OwBSMuyEBMOyv5oEBp5n+a5XAQhv8zFhbT5j+a7/480wfYZ5Pb+TYcmSJezZsweANWvWEBjowoPx7McwzyS1RlgeYZ4LgYbeDIjbRu72xmMny0JY8GhvHl00Evs3SWSlxnHj6CpSHj8N51bj7x3UxxL+3dshtIDv/o0ufA1yZhm88PZQ/vjfjzvuwe3bGc4HW2d5McaW86590zW30XC9LrafOnVqazRrCTv/0oHiT9pRXxfA395v7A49OPs4A4dd9HJk8q++Of8Qab/NICjYpOxQKDve7OjtkHxGa42itjRNE2lh3XrV8cKbXzZ5bPSd53nzq2JvhCZOmnFvXwDqG6L53a/6ejka33XddlF/zNq1az11KRFpZY2L7ZXgRMSiVMGJiDWZzi+29yYlOBFxmQk02DXIICIWpHtwImJp6qKKiEXpHpyIWNR1vVRLRKzPpkEGEbEiDTKIiIXpHpyIWJg/PL5dCU5EXKZBBhGxNFVwImJJJmCzK8GJiCUZGkUVEetSF1VELEmDDCJiaaYfvC1JCU5E3KIuqohYkomhtagiYlGmuqgiYmHqooqIZSnBiYhl+UEPVQlORFxnmmBqqZaIWJW6qCJiWf4wiur7E1lExAcZmKZzmzP27dtHWloaAKWlpYwfP57U1FSysrKw2+0ALFu2jHvvvZdx48ZRXFzsVLuq4ETEPS3URV25ciVbt24lLCwMgAULFpCRkcGIESPIzMxk+/bt9OjRg127drFp0yZOnDhBeno6mzdvbrbtJhPcxo0bm/ymlJQUN34MEbGMFpzoGxMTQ05ODjNmzADgwIEDJCQkADB27Fg++ugjYmNjGTNmDIZh0KNHD2w2G5WVlURFRV217SYTXEVFRctELyKWY+L8KGplZSWTJ0927KekpFxRJCUmJlJeXv5d26aJYTS2HR4ezoULF6iqqqJjx46Ocy4fdzvBPf74446vd+7cSVlZGTfeeCOxsbFO/VAiYnFOVnBRUVEUFBQ43WxAwHdDA9XV1bRv35527dpRXV19xfGIiIjm22ruhMWLF7Nlyxby8/M5ePAgs2fPdjpQEbGulhxk+L6BAwdSVFQEQGFhIcOGDeOmm27iww8/xG63c/z4cex2e7PVGziR4Hbv3s3ChQtp27Yt99xzzxWlpIhcp0wXNhfNnDmTnJwcUlJSqK+vJzExkUGDBjFs2DBSUlJIT08nMzPTqbaaHUW12WzU1tZiGAY2m+2K8lFErmctN9E3Ojqa/Px8AGJjY1m3bt0PzklPTyc9Pd2ldptNcA888ABJSUlUVlZy3333MXHiRJcuICIWZfd2AM1rNsHdeeed3HzzzXz99ddER0cTGRnpibhExKcZLTYPrjU1m+D2799PVlYW33zzDT169ODJJ59kwIABnohNRHyYPyzVajbBzZ8/n4ULF9K3b1/+8Y9/8OSTT5KXl+eJ2ETEV7k5gOBpzSa40NBQ+vbtC8CAAQMIDg5u9aBExA/4cxf18lKtoKAgsrOzGT58OMXFxbRr185jwYmI7zL8uYK7vFRryJAhAHz11VdEREQQHx/vmchExLf58wMvv79U6/Tp0zQ0NGCaJqdPn/ZIYCLiw6xyD27OnDns3buXmpoaLl26RK9evRwT8kTkOuYHCa7ZZQklJSVs27aNMWPGsG3bNkJDQz0Rl4j4ulZaqtWSmq3gIiMjMQyDixcvOrW4VUSuE/48inrZT3/6U1atWkWXLl2YOnUqNTU1nohLRHycX4+iXjZt2jSqq6sJDQ2lsLCQG2+80RNxiYgv84HupzOaTHDPP/+846ma37d3716mTZvWqkGJiG8z8PMKLi4uzpNxOJR83ZlJs3/jlWu3tlULrPmzZR5a7e0QWkXXnjVMP3TA22H4Ln++B3fPPfd4Mg4R8Tf+XMGJiFyVEpyIWJIJhhUeeHnq1CkWLVpEZWUld9xxBwMGDNBIqoj4RQXX7EqGefPm8atf/Yr6+nqGDRvG/PnzPRGXiPg4w3Ru86ZmE9ylS5cYNWoUhmEQFxenpVoiguOR5c5sXuTUAy937NiB3W5n7969hISEeCIuEfFlfjLRt9kK7umnn6agoICzZ8+yevVqsrOzPRCWiPg6f+iiNlvBdevWjSVLlngiFhHxI5YYRR0zZozj63PnztGrVy/+/Oc/t2pQIuIH/KCL2myC+/DDDx1fHzt2jGXLlrVqQCLiB/zkHpxLE3179uzJkSNHWisWEfETfr/Y/rJp06Y5nipy+vRpOnXq1OpBiYi0hGYT3F133UX79u2BxikjgwYNavWgRMQPWKGCW7VqFevXr/dELCLiRywxitqhQwdefvllYmNjCQhonDb3/ZFVEbkOWWWQITIykpKSEkpKShzHlOBExK8HGTIyMli6dCkLFizwZDwi4i/8OcFVVlZ6Mg4R8TN+XcGVlZWxePHiH/1ML50Ruc6ZgD8PMrRp04bY2FhPxiIifqSlKrj6+npmzZrFsWPHCAgI4OmnnyYoKIhZs2ZhGAb9+vUjKyvLMcjpiiYT3A033KAXz4hI01oowX3wwQc0NDSwYcMGPvroI5YuXUp9fT0ZGRmMGDGCzMxMtm/fzu233+5y202mRE3oFZGrMp3cmhEbG4vNZsNut1NVVUVQUBAHDhwgISEBgLFjx7Jz5063Qmyygps5c6ZbDYqI9bmyFrWyspLJkyc79lNSUkhJSXHst23blmPHjnHnnXdy9uxZXnzxRT799FPHEtHw8HAuXLjgVpx6q5aIuM6Fib5RUVEUFBQ0+fmaNWsYM2YM06dP58SJEzzwwAPU19c7Pq+urnYsF3WV63ftRERoXKrlzNac9u3bExERATSunGpoaGDgwIEUFRUBUFhYyLBhw9yKURWciLinhQYZJk6cyJw5c0hNTaW+vp6pU6cyaNAg5s2bx+LFi4mLiyMxMdGttpXgRMQtLfW+rPDwcF544YUfHF+3bt01t60EJyLu8eeVDCIiTfKBN2Y5QwlORNyjBCciVmWJB16KiPwoVXAiYkW+8NZ6ZyjBiYh7lOBExKpUwYmIdWmQQUQsSffgRMTSlOBExJpMDNP3M5wSnIi4x/fzmxKciLhH9+BExJIMU0u1RMTKVMGJiFWpiyoi1uTCS2e8SQlORNyiCk5ELMuw+36GU4ITEff4fn5TghMRN2iayPVtwu2fMWZQKcFBdgp2DGT4gHJ6tdlFTvopukVd4MDRLmS//B/eDlOAE3vDKFzYlZS8o5z5MpR3nugOpsHugVsY8gQE/POv5OKZQDakxHL/tsMEhfpB+dLa/OBX4LE32+/bt4+0tDRPXc6rhvQ9zr/FnuLRpXfz+Au/pGtkFdkv/wdll/4vc176T6pqQsl5/WZvhynArtxOvDOnB7baxrd87ni+C7dMP834/K8AOPxe4xvXjxaG89rE3lRXqCaAxneiXn6qb3ObN3kkwa1cuZInnniC2tpaT1zO6xLiyzl8PIrfT36HZ3/zFz76e2/HZ//7rr/xWuFPOfNtWy9GKJd1jKnjv/5Q5tj/r+VlRCdcxFZncO5UFaER/+yHBcB9r5TSpqPNS5H6INN0bvMij/zvKCYmhpycHGbMmNHsud07t2fVggkeiKr1dA05TnDAScovrSbYOMGK6bP5qmYdP+kOP7mlmqM1y0i6O9DbYbaYHj3v8HYIbhs1CU6XnmNHyGuM6vksABWl53jyl2uJ6GjjrtuWE9GpLaNSGs/fFLiUET2eJKTNdV7J6R7cdxITEykvL3fq3BMV3zJp9rpWjqh1PfLLMs5VhbHh/Y0ArJlZzfTlL7Eq6wbeePcGXnlnvZcjbFmZz6z2dgjX5PzJYKrqovn4WHLjgSD49dtQ/c4sFqXP5c5Fxxzn1tr6UXT8135/D+6OuM+vuQ1vdz+d4bF7cNeT4iPdGBFfBph0al9Nm5AGvq0OpW3g3/jk8xhvhydX8frDvTh7NASAsHYhGAF+8FfsLeqiXp92HujNjX1OsHL6FgICTBZvGo3dDCAkoIzjZ+K8HZ5cRcIj3/CXGT0JDDbpHFnMmMzT3g7JZ/lDBacE10pWbB35g2NHa16hqsa/u99W1CG6ntTNjaOmPW+qcYygjuq5kI+Pbbni3Ic++NLT4fkmrUW9UnR0NPn5+Z66nIi0MlVwImJdNt/PcEpwIuIyX5jE6wwlOBFxg/dHSJ2hBCciblEFJyLW1YIJ7o9//CPvvfce9fX1jB8/noSEBGbNmoVhGPTr14+srCwCAlyftquJviLiOhMMm+nU1pyioiI+++wz1q9fz9q1azl58iQLFiwgIyODvLw8TNNk+/btboWpBCcibjFM06mtsrKSpKQkx7Zx48Yr2vnwww/p378/jz32GI888gi33norBw4cICEhAYCxY8eyc+dOt2JUF1VE3ONkFzUqKoqCgoImPz979izHjx/nxRdfpLy8nEcffRTTNDGMxkdYhYeHc+HCBbdCVIITEfe00Chqx44diYuLIyQkhLi4OEJDQzl58qTj8+rqatq3b+9W2+qiiojrnHzYpTMjrUOHDmXHjh2YpsmpU6eoqalh1KhRFBUVAVBYWMiwYcPcClMVnIi4p4UquNtuu41PP/2Ue++9F9M0yczMJDo6mnnz5rF48WLi4uJITEx0q20lOBFxmYFzI6TO+rGH4a5bd+0PplCCExHX6WkiImJlhpZqiYhlKcGJiGXppTMiYkmmuqgiYlkm2H2/hFOCExH3+H5+U4ITETeoiyoilqYEJyKWpQQnIpZkordqiYhVmboHJyIWpgQnIpZlV4ITESsyUQUnIhamBCci1mSCzfeXMijBiYjrTMBUghMRq1IXVUSsydQoqohYmCo4EbEkTRMREesywWbzdhDNUoITEfeoghMRS1IXVUQsTaOoImJNJqYm+oqIJZloqZaIWJheGygilmSaGmQQEesyVcGJiGWpghMRSzK12F5ELMz0g6VaAd4OQET8kdn4wEtnNiecOXOGn/3sZxw+fJjS0lLGjx9PamoqWVlZ2K/hXp8SnIi4zgTTbjq1Nae+vp7MzEzatGkDwIIFC8jIyCAvLw/TNNm+fbvbYSrBiYh7WqiCe/bZZxk3bhxdunQB4MCBAyQkJAAwduxYdu7c6XaIPncPLr5PN3bm/9bbYbQaa/5sVvyZGt0R97m3Q/BJ/Yf14V37JqfOPXHiBI899phjPyUlhZSUFAAKCgqIiorilltuITc3FwDTNDEMA4Dw8HAuXLjgdpw+l+BExFq6d+9OQUHBj362efNmDMPg448/5uDBg8ycOZPKykrH59XV1bRv397tayvBiYjXvPrqq46v09LSyM7OZtGiRRQVFTFixAgKCwsZOXKk2+3rHpyI+JSZM2eSk5NDSkoK9fX1JCYmut2WYZp+MB1ZRMQNquBExLKU4ETEspTgRMSylOA8pKamhnHjxnH48GFvhyJO2rdvH2lpad4OQ66Bpol4wP79+8nKyuLUqVPeDkWctHLlSrZu3UpYWJi3Q5FroArOA+rq6li+fDlxcXHeDkWcFBMTQ05OjrfDkGukCs4Dhg4d6u0QxEWJiYmUl5d7Owy5RkpwrWTJkiXs2bMHgDVr1hAYGOjliESuP0pwrWTq1KneDkHkuqd7cCJiWVqqJSKWpQpORCxLCU5ELEsJTkQsSwlORCxLCU5ELEsJzs8VFRUxatQo0tLSSEtLIzk5mbVr17rV1nPPPUdBQQEHDx5k2bJlTZ737rvvOr2utrCwkFmzZv0g5qvNEywoKOC5555zqn1XzpXrjyb6WsDIkSNZsmQJ0Lju9Y477uDuu+92+2Ud8fHxxMfHN/n5K6+8QnZ2Nl27dnWrfRFPUYKzmKqqKgICAggMDCQtLY2oqCjOnz9Pbm4u2dnZlJaWYrfbycjIYMSIEbz99tusWLGCqKgo6uvriYuLo6ioiA0bNrBkyRI2bdrE+vXrsdvt/PznP2fw4MGOtx/l5eWxceNG3nzzTQzD4K677uL+++/n8OHDzJkzh7CwMMLCwujQoUOT8a5bt4533nmHmpoaIiMjHZXj3r17eeCBB6iqqiI9PZ1bb72VXbt2sWTJEgIDA+nVqxdPPfWUp36t4qeU4Czgk08+IS0tDcMwCA4OZt68eYSHhwPwi1/8gttvv528vDwiIyP5/e9/z9mzZ5kwYQJbtmzhmWeeoaCggI4dO/Lwww9f0e6ZM2ccjw0KDQ3l+eefZ/jw4cTHx5Odnc3XX3/NW2+9RV5eHgAPPvggY8aMYeHChUyZMoXRo0eTm5vLkSNHfjRuu93OuXPnWLNmDQEBAUyaNIn9+/cDEBYWRm5uLpWVldx3333ccsstzJs3j7y8PDp16sTSpUt5/fXXCQrSP2Fpmv51WMD3u6j/KjY2FoAvvviC3bt3U1xcDEBDQwMVFRV06NCByMhIAIYMGXLF95aVldGvXz/atGkDwG9/e+ULnr/44guOHz/OxIkTATh//jylpaUcPXqUwYMHA3DTTTc1meACAgIIDg5m2rRptG3blpMnT9LQ0AA0PoHFMAw6depEREQEZ8+e5fTp02RkZABw6dIlbr75Znr37u3Kr0quM0pwFnf5DeFxcXF069aNRx55hEuXLrFixQpuuOEGvv32WyorK4mKimL//v1069bN8b0xMTEcOXKEuro6QkJCmDJlCnPnzsUwDEzTJC4ujr59+/LSSy9hGAZr1qxhwIAB9OnTh88++4yxY8fy97//vcnYSkpK+Otf/8qmTZuoqakhKSmJyysHL1dyFRUVXLx4kcjISLp168Yf/vAHIiIi2L59O23btuXEiROt+NsTf6cEd50YN24cTzzxBBMmTKCqqorU1FRCQkLIzMxk0qRJdOjQ4QfdvaioKB566CEmTJiAYRjcdtttdO3alSFDhjBjxgxWr17NqFGjGD9+PHV1dQwePJiuXbsya9YsZs6cyapVq4iKiiI0NPRHY+rduzdhYWGMGzcOgM6dO3P69GmgsUK7//77uXjxIk899RSBgYHMnTuXhx9+GNM0CQ8PZ+HChUpwclVabC8ilqV5cCJiWUpwImJZSnAiYllKcCJiWUpwImJZSnAiYllKcCJiWf8fgcCiHifItm0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(clf_svm,t_t()[1],  t_t()[3], values_format='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    # running the model and getting the accuracy\n",
    "    model_SVM = SVM(C = 100, sigma = 2, toler=0.001, maxIter=40)\n",
    "    b, alphas = model_SVM.fit(t_t()[0], t_t()[2])\n",
    "    y_test_hat = model_SVM.predict(t_t()[1])\n",
    "    accuracy = np.mean(y_test_hat == t_t()[3])\n",
    "    print(\"The accuracy of SVM is:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of SVM is: 0.7026315789473684\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am doing okayish here, but let's see what the sklearn library can offered me to resolve it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I again use the processed data from the logistic regression but this time I specify SVC\n",
    "\n",
    "SVM_best_scores = {}\n",
    "\n",
    "for key, val in train_sets.items():\n",
    "    preprocess = preprocess_dict[key+'_scaled']\n",
    "    model = make_pipeline(preprocess, SVC())\n",
    "    params = {\n",
    "              \n",
    "              'svc__C': [.01,.01,.1,1,10,100,1000],\n",
    "              'svc__gamma':['auto',.0001,.001,.01,.1,1,10,100], \n",
    "              'svc__class_weight':['balanced',None]\n",
    "              }\n",
    "\n",
    "    search_svm = GridSearchCV(estimator = model, param_grid = params,\n",
    "                     cv = 5, return_train_score = True,\n",
    "                      n_jobs = -1)\n",
    "\n",
    "    search_svm.fit(val[0], val[1])\n",
    "    SVM_best_scores[key] = {'model':search_svm, 'best_params':search_svm.best_params_,\n",
    "                           'best_score':search_svm.best_score_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA=.5_train :  0.6666191872643485\n"
     ]
    }
   ],
   "source": [
    "# See which dataframe varying by MA detection feature had the best score. \n",
    "\n",
    "for key in train_sets.keys():\n",
    "    print(key, ': ',LR_best_scores[key]['best_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 10, 'svc__class_weight': 'balanced', 'svc__gamma': 'auto'}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_best_scores['MA=.5_train']['best_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suppot vector machine\n",
      "Accuracy Score:  0.6605263157894737\n",
      "Precision Score:  0.7552447552447552\n",
      "Recall Score:  0.5346534653465347\n",
      "F1 Score:  0.6260869565217392\n"
     ]
    }
   ],
   "source": [
    "# Generate classifier metrics for this optimal classifier. \n",
    "\n",
    "y_hat_test_MA5_SVM = SVM_best_scores['MA=.5_train']['model'].predict(X_test_MA5)\n",
    "print('Suppot vector machine')\n",
    "print('Accuracy Score: ', accuracy_score(y_test_MA5,y_hat_test_MA5_SVM))\n",
    "print('Precision Score: ', precision_score(y_test_MA5,y_hat_test_MA5_SVM))\n",
    "print('Recall Score: ', recall_score(y_test_MA5,y_hat_test_MA5_SVM))\n",
    "print('F1 Score: ',f1_score(y_test_MA5,y_hat_test_MA5_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model for ROC curve. \n",
    "\n",
    "y_scores_SVM = SVM_best_scores['MA=.5_train']['model'].decision_function(X_test_MA5)\n",
    "fpr_SVM, tpr_SVM, threshold_SVM = roc_curve(y_test_MA5, y_scores_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7295027255534542\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate ROC curve. \n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "print('AUC: {}'.format(auc(fpr_SVM, tpr_SVM)))\n",
    "plt.figure(figsize=(10,8))\n",
    "lw = 2\n",
    "plt.plot(fpr_SVM, tpr_SVM, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qual_assess</th>\n",
       "      <th>pre_screen</th>\n",
       "      <th>MA_detection_.5</th>\n",
       "      <th>MA_detection_.6</th>\n",
       "      <th>MA_detection_.7</th>\n",
       "      <th>MA_detection_.8</th>\n",
       "      <th>MA_detection_.9</th>\n",
       "      <th>MA_detection_1.0</th>\n",
       "      <th>exudate_detection_.3</th>\n",
       "      <th>exudate_detection_.4</th>\n",
       "      <th>exudate_detection_.5</th>\n",
       "      <th>exudate_detection_.6</th>\n",
       "      <th>exudate_detection_.7</th>\n",
       "      <th>exudate_detection_.8</th>\n",
       "      <th>exudate_detection_.9</th>\n",
       "      <th>exudate_detection_1.0</th>\n",
       "      <th>euc_dist</th>\n",
       "      <th>diam_opt_disc</th>\n",
       "      <th>AM/FM</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>49.895756</td>\n",
       "      <td>17.775994</td>\n",
       "      <td>5.270920</td>\n",
       "      <td>0.771761</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.486903</td>\n",
       "      <td>0.100025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>57.709936</td>\n",
       "      <td>23.799994</td>\n",
       "      <td>3.325423</td>\n",
       "      <td>0.234185</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>55.831441</td>\n",
       "      <td>27.993933</td>\n",
       "      <td>12.687485</td>\n",
       "      <td>4.852282</td>\n",
       "      <td>1.393889</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.530904</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qual_assess  pre_screen  MA_detection_.5  MA_detection_.6  MA_detection_.7  \\\n",
       "0          1.0         1.0             22.0             22.0             22.0   \n",
       "1          1.0         1.0             24.0             24.0             22.0   \n",
       "2          1.0         1.0             62.0             60.0             59.0   \n",
       "\n",
       "   MA_detection_.8  MA_detection_.9  MA_detection_1.0  exudate_detection_.3  \\\n",
       "0             19.0             18.0              14.0             49.895756   \n",
       "1             18.0             16.0              13.0             57.709936   \n",
       "2             54.0             47.0              33.0             55.831441   \n",
       "\n",
       "   exudate_detection_.4  exudate_detection_.5  exudate_detection_.6  \\\n",
       "0             17.775994              5.270920              0.771761   \n",
       "1             23.799994              3.325423              0.234185   \n",
       "2             27.993933             12.687485              4.852282   \n",
       "\n",
       "   exudate_detection_.7  exudate_detection_.8  exudate_detection_.9  \\\n",
       "0              0.018632              0.006864              0.003923   \n",
       "1              0.003903              0.003903              0.003903   \n",
       "2              1.393889              0.373252              0.041817   \n",
       "\n",
       "   exudate_detection_1.0  euc_dist  diam_opt_disc  AM/FM class_label  \n",
       "0               0.003923  0.486903       0.100025    1.0        b'0'  \n",
       "1               0.003903  0.520908       0.144414    0.0        b'0'  \n",
       "2               0.007744  0.530904       0.128548    0.0        b'1'  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I am loading the full dataset and renaming the columns to keep better track of each attribute\n",
    "data_dir = \"..\\..\\..\\data\\data_classification\"\n",
    "data_path = os.path.join(data_dir, \"messidor_classification.csv\")\n",
    "df = pd.read_csv(data_path, header=0)\n",
    "col_names = ['qual_assess','pre_screen','MA_detection_.5','MA_detection_.6','MA_detection_.7','MA_detection_.8',\n",
    "             'MA_detection_.9','MA_detection_1.0','exudate_detection_.3','exudate_detection_.4','exudate_detection_.5','exudate_detection_.6'\n",
    "             ,'exudate_detection_.7','exudate_detection_.8','exudate_detection_.9','exudate_detection_1.0',\n",
    "             'euc_dist','diam_opt_disc','AM/FM','class_label']\n",
    "df.columns = col_names\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets function\n",
    "def load_data(data_file_name):\n",
    "    data_dir = \"..\\..\\..\\data\\data_classification\"\n",
    "    data_path = os.path.join(data_dir, data_file_name)\n",
    "    df = pd.read_csv(data_path, header=1)\n",
    "    data_X = df.iloc[:,:-1]\n",
    "    data_y = df.iloc[:,-1]\n",
    "    scaler_X = StandardScaler()\n",
    "    data_X = scaler_X.fit_transform(data_X)\n",
    "    data_y = pd.Categorical(data_y).codes.reshape(-1)\n",
    "    return data_X, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide each new dataframe between variables and target. \n",
    "\n",
    "X = df.iloc[:,0:-1]\n",
    "y = df.class_label\n",
    "\n",
    "X_MA5 = df_MA5.iloc[:,0:-1]\n",
    "y_MA5 = df_MA5.class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a test-train split for each dataframe.\n",
    "\n",
    "X_train_MA5, X_test_MA5, y_train_MA5, y_test_MA5 = train_test_split(X_MA5,y_MA5, \n",
    "                                                                    test_size = .33, \n",
    "                                                                    random_state = 27,\n",
    "                                                                    stratify = y_MA5)\n",
    "\n",
    "                                                                    \n",
    "train_sets = {'MA=.5_train':(X_train_MA5,y_train_MA5)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "\n",
    "    # read dataset from csv file\n",
    "    data_name = \"messidor_classification\"\n",
    "    data_X, data_y = load_data(\"{}.csv\".format(data_name))\n",
    "\n",
    "    return data_X, data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterion -- Gini Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_counts(y, sample_weight, classes_):\n",
    "    '''\n",
    "    the function used to calculate the summation of weights of samples from each class. Generally speaking,\n",
    "    the weights are all set as one. But for Adaboost, each sample has different values.\n",
    "    '''\n",
    "    class_counts = np.zeros(shape=classes_.shape[0], dtype=np.float64)\n",
    "    for i, label in enumerate(classes_):\n",
    "        idx = y == label\n",
    "        if idx.sum() > 0:\n",
    "            class_counts[i] = sample_weight[idx].sum()\n",
    "        else:\n",
    "            class_counts[i] = 0\n",
    "    return class_counts\n",
    "\n",
    "def gini(y, sample_weight):\n",
    "    classes_ = np.unique(y)\n",
    "    class_counts = calculate_weighted_counts(y, sample_weight, classes_)\n",
    "    if class_counts.sum() > 0:\n",
    "        pk = class_counts / class_counts.sum()\n",
    "        pk = pk[pk > 0]\n",
    "        return 1 - np.sum(pk**2)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def gini_index(X, y, feat, point, sample_weight):\n",
    "    '''\n",
    "    calculate the difference of gini index before and after splitting\n",
    "    '''\n",
    "    S = gini(y, sample_weight)\n",
    "    new_S = 0\n",
    "    n = sample_weight.sum()\n",
    "    assert n > 0\n",
    "    idx1 = X[:, feat] < point\n",
    "    nv = sample_weight[idx1].sum()\n",
    "    if nv > 0:\n",
    "        new_S += nv / n * gini(y[idx1], sample_weight[idx1])\n",
    "    idx2 = X[:, feat] >= point\n",
    "    nv = sample_weight[idx2].sum()\n",
    "    if nv > 0:\n",
    "        new_S += nv / n * gini(y[idx2], sample_weight[idx2])\n",
    "    return S - new_S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Decision Trees for Classification\n",
    "\n",
    "Different from the classification tree implemented in the last tutorial:\n",
    "1. Each internal node has two child nodes regardless of values of the splitting feature are continuous or discrete.\n",
    "2. Add the parameter `max_depth` for providing another condition to stop splitting procedures.\n",
    "3. Add the parameter `max_features` to use the subset of features to build decision tree.\n",
    "\n",
    "Options 2&3 are designed for constructing trees in the random forest implemented in Section 5. \n",
    "\n",
    "If you'd like to build the classification tree, you can ignore options 2&3 by setting `max_depth = None` and `max_features = None`. Then we can combine it with the pre-pruning or post-pruning technique implemented in Section 4 to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(object):\n",
    "    '''\n",
    "    This class is for classification tree\n",
    "\n",
    "    Attributes:\n",
    "        - criterion: a function used as the criterion of classification tree\n",
    "        - tree: a nested dictionary representing the decision tree structure.\n",
    "        - max_depth: the parameter to control the depth of tree. If the depth is larger than max_depth, we will stop splitting.\n",
    "        - max_feature: the number of selected features to build decision tree\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 criterion=gini_index,\n",
    "                 max_depth=None,\n",
    "                 max_features=None,\n",
    "                 random_seed=None):\n",
    "        self.f_criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        if self.max_depth is None:\n",
    "            self.max_depth = 2**10\n",
    "        self.max_features = max_features\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        np.random.seed(self.random_seed)\n",
    "        num_samples, num_features = X.shape\n",
    "        if self.max_features is None:\n",
    "            self.max_features = num_features\n",
    "        elif self.max_features == \"sqrt\":\n",
    "            self.max_features = np.int(np.round(np.sqrt(num_features)))\n",
    "        self.classes_ = np.unique(y)\n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones(num_samples, dtype=np.float64)\n",
    "        # build the decision tree\n",
    "        self.tree = self.create_tree(X, y, sample_weight, depth=0)\n",
    "\n",
    "    def create_tree(self, X, y, sample_weight, depth):\n",
    "        Tree = {}\n",
    "        Tree[\"depth\"] = depth\n",
    "        class_counts = calculate_weighted_counts(y, sample_weight, self.classes_)\n",
    "        # create a leaf node if all samples belong to the same class\n",
    "        if (class_counts != 0).sum() == 1:\n",
    "            Tree[\"is_leaf\"] = True\n",
    "            Tree[\"pred\"] = self.classes_[class_counts != 0]\n",
    "        # using the majority vote to get the prediction at each node\n",
    "        majority_class = self.classes_[np.argmax(class_counts)]\n",
    "        Tree[\"pred\"] = majority_class\n",
    "        # create a leaf node if feature set is empty\n",
    "        feat, point = self.choose_best_split(X, y, sample_weight)\n",
    "        if feat is None or depth == self.max_depth:\n",
    "            Tree[\"is_leaf\"] = True\n",
    "            return Tree\n",
    "        # otherwise, create an internal node\n",
    "        Tree[\"is_leaf\"] = False\n",
    "        Tree[\"split_feat\"] = feat\n",
    "        Tree[\"split_point\"] = point\n",
    "        # build the left subtree\n",
    "        idx = X[:, feat] < point\n",
    "        Tree[\"left\"] = self.create_tree(X[idx], y[idx], sample_weight[idx],\n",
    "                                        depth + 1)\n",
    "        # build the right subtree\n",
    "        idx = X[:, feat] >= point\n",
    "        Tree[\"right\"] = self.create_tree(X[idx], y[idx], sample_weight[idx],\n",
    "                                         depth + 1)\n",
    "        return Tree\n",
    "\n",
    "    def choose_best_split(self, X, y, sample_weight):\n",
    "        # initialization\n",
    "        best_feat, best_point = None, None\n",
    "        best_score = 0.0\n",
    "        # search for each candidate feature\n",
    "        num_features = X.shape[1]\n",
    "        if self.max_features < num_features:\n",
    "            candidate_feat = np.random.permutation(\n",
    "                num_features)[:self.max_features]\n",
    "        else:\n",
    "            candidate_feat = np.arange(num_features)\n",
    "        for feat in candidate_feat:\n",
    "            # if all values of this feature are equal, do not split this feature\n",
    "            X_feat_value = np.unique(X[:, feat])\n",
    "            if len(X_feat_value) == 1:\n",
    "                continue\n",
    "            # search for each possible split point\n",
    "            for i in range(len(X_feat_value) - 1):\n",
    "                # divide the dataset into two parts according to the split\n",
    "                point = (X_feat_value[i] + X_feat_value[i + 1]) / 2.0\n",
    "                # calculate score to evaluate the quality of a split\n",
    "                score = self.f_criterion(X, y, feat, point, sample_weight)\n",
    "                if score > best_score:\n",
    "                    best_feat = feat\n",
    "                    best_point = point\n",
    "                    best_score = score\n",
    "        return best_feat, best_point\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        function used to fit the decision tree classifier\n",
    "\n",
    "        Args:\n",
    "            X - features of test samples, a pandas dataframe with shape (n, d)\n",
    "\n",
    "        Returns:\n",
    "            y - predictions of test samples, a pandas series with shape (n,)\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "        y = []\n",
    "        for i in range(n):\n",
    "            y.append(DecisionTreeClassifier.predict_each(X[i], self.tree))\n",
    "        y = np.array(y, dtype=np.int32)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def predict_each(x, tree):\n",
    "        '''\n",
    "        for each sample, get the prediction of decision tree classifier in a recursive manner.\n",
    "\n",
    "        Args:\n",
    "            x - features of a sample, a pandas Series with shape (d,)\n",
    "            tree - a nested dictionary representing the decision tree structure.\n",
    "\n",
    "        Returns:\n",
    "            the prediction of the sample `x`\n",
    "        '''\n",
    "        if tree[\"is_leaf\"] is True:\n",
    "            # if the `tree` is a leaf node, get the prediction at the leaf node\n",
    "            return tree[\"pred\"]\n",
    "        else:\n",
    "            # the 'tree' is a nested dictionary\n",
    "            # get the value of the feature used to split\n",
    "            feat = tree[\"split_feat\"]\n",
    "            point = tree[\"split_point\"]\n",
    "            # get the value of the feature for the sample `x`\n",
    "            value = x[feat]\n",
    "            if value < point:\n",
    "                return DecisionTreeClassifier.predict_each(x, tree[\"left\"])\n",
    "            else:\n",
    "                return DecisionTreeClassifier.predict_each(x, tree[\"right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_t():\n",
    "    # Randomly assingning a train and test set\n",
    "    train_X, test_X, train_y, test_y = train_test_split(main()[0], main()[1], test_size=0.33, random_state=100)\n",
    "    return train_X, test_X, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of training data is: 1.0\n",
      "The accuracy of test data is: 0.6447368421052632\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = t_t()\n",
    "model = DecisionTreeClassifier(criterion=gini_index,\n",
    "                                   max_depth=None,\n",
    "                                   max_features=None,\n",
    "                                   random_seed=None)\n",
    "model.fit(X_train, y_train)\n",
    "y_train_hat = model.predict(X_train)\n",
    "y_test_hat = model.predict(X_test)\n",
    "acc_train = (y_train == y_train_hat).mean()\n",
    "acc_test = (y_test == y_test_hat).mean()\n",
    "print(\"The accuracy of training data is:\", acc_train)\n",
    "print(\"The accuracy of test data is:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You maybe find that the accuracy of training data is almost one but the accuracy of test data is low. The reason is that the decision tree overfits to the training data. To prevent overfitting, we introduce the post-pruning technique in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classification Tree with the Pruning Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning(tree, classes_, X_valid, y_valid):\n",
    "    '''\n",
    "    the function used to post-prune the decision tee\n",
    "\n",
    "    Args:\n",
    "        tree - a nested dictionary representing the decision tree structure.\n",
    "        classes_ - names of all classes \n",
    "        X_valid - the features of the validation samples\n",
    "        y_valid - the labels of the validation samples\n",
    "    Returns:\n",
    "        the tree structure after pruning\n",
    "   '''\n",
    "    if X_valid.shape[0] == 0:\n",
    "        new_tree = {}\n",
    "        new_tree[\"is_leaf\"] = True\n",
    "        new_tree[\"pred\"] = tree[\"pred\"]\n",
    "        return new_tree\n",
    "    if tree[\"is_leaf\"] is True:\n",
    "        return tree\n",
    "    feat = tree[\"split_feat\"]\n",
    "    point = tree[\"split_point\"]\n",
    "    idx1 = X_valid[:, feat] < point\n",
    "    tree[\"left\"] = pruning(tree[\"left\"], classes_, X_valid[idx1],\n",
    "                           y_valid[idx1])\n",
    "    idx2 = X_valid[:, feat] >= point\n",
    "    tree[\"right\"] = pruning(tree[\"right\"], classes_, X_valid[idx2],\n",
    "                            y_valid[idx2])\n",
    "    if tree[\"left\"][\"is_leaf\"] is True and tree[\"right\"][\"is_leaf\"] is True:\n",
    "        FLAG = True\n",
    "    else:\n",
    "        FLAG = False\n",
    "    if FLAG:\n",
    "        # check validation accuracy gap\n",
    "        valid_y_true = []\n",
    "        valid_y_pred = []\n",
    "        # make prediction and calculate validation accuracy of the tree before merging\n",
    "        child_majority_class = tree[\"left\"][\"pred\"]\n",
    "        idx1 = X_valid[:, feat] < point\n",
    "        if idx1.sum() > 0:\n",
    "            valid_y_true.append(y_valid[idx1])\n",
    "            valid_y_pred.append([child_majority_class] * idx1.sum())\n",
    "        child_majority_class = tree[\"right\"][\"pred\"]\n",
    "        idx2 = X_valid[:, feat] >= point\n",
    "        if idx2.sum() > 0:\n",
    "            valid_y_true.append(y_valid[idx2])\n",
    "            valid_y_pred.append([child_majority_class] * idx2.sum())\n",
    "        valid_y_true = np.concatenate(valid_y_true)\n",
    "        valid_y_pred = np.concatenate(valid_y_pred)\n",
    "        valid_acc_before = np.mean(valid_y_true == valid_y_pred)\n",
    "        # make prediction and calculate validation accuracy of the tree after merging\n",
    "        majority_class = tree[\"pred\"]\n",
    "        valid_y_pred = np.array([majority_class] * X_valid.shape[0])\n",
    "        valid_acc_after = np.mean(valid_y_true == valid_y_pred)\n",
    "        # if the validation accuracy after merging is larger, we will prune\n",
    "        if valid_acc_after > valid_acc_before:\n",
    "            new_tree = {}\n",
    "            new_tree[\"is_leaf\"] = True\n",
    "            new_tree[\"pred\"] = tree[\"pred\"]\n",
    "            return new_tree\n",
    "        else:\n",
    "            return tree\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of the classification tree Without pruning is: 1.0\n",
      "Validation accuracy of the classification tree Without pruning is: 0.5714285714285714\n",
      "Testing accuracy of the classification tree Without pruning is: 0.6342105263157894 \n",
      "\n",
      "Training accuracy of the classification tree With pruning is: 0.974025974025974\n",
      "Validation accuracy of the classification tree With pruning is: 0.6017316017316018\n",
      "Testing accuracy of the classification tree With pruning is: 0.6289473684210526\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = t_t()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train,\n",
    "                                                      y_train,\n",
    "                                                      test_size=0.3,\n",
    "                                                      stratify=y_train,\n",
    "                                                      random_state=3147)\n",
    "model = DecisionTreeClassifier(criterion=gini_index,\n",
    "                                   max_depth=None,\n",
    "                                   max_features=None,\n",
    "                                   random_seed=None)\n",
    "model.fit(X_train, y_train)\n",
    "# without pruning\n",
    "y_train_hat = model.predict(X_train)\n",
    "y_valid_hat = model.predict(X_valid)\n",
    "y_test_hat = model.predict(X_test)\n",
    "acc_train = (y_train == y_train_hat).mean()\n",
    "acc_valid = (y_valid == y_valid_hat).mean()\n",
    "acc_test = (y_test == y_test_hat).mean()\n",
    "print(\"Training accuracy of the classification tree Without pruning is:\", acc_train)\n",
    "print(\"Validation accuracy of the classification tree Without pruning is:\", acc_valid)\n",
    "print(\"Testing accuracy of the classification tree Without pruning is:\", acc_test, '\\n')\n",
    "# with pruning\n",
    "model.tree = pruning(model.tree, model.classes_, X_valid, y_valid)\n",
    "y_train_hat = model.predict(X_train)\n",
    "y_valid_hat = model.predict(X_valid)\n",
    "y_test_hat = model.predict(X_test)\n",
    "acc_train = (y_train == y_train_hat).mean()\n",
    "acc_valid = (y_valid == y_valid_hat).mean()\n",
    "acc_test = (y_test == y_test_hat).mean()\n",
    "print(\"Training accuracy of the classification tree With pruning is:\", acc_train)\n",
    "print(\"Validation accuracy of the classification tree With pruning is:\", acc_valid)\n",
    "print(\"Testing accuracy of the classification tree With pruning is:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Random Forest for Classification\n",
    "\n",
    "In this section, we implement the random forest where each tree is built with the class DecisionTreeClassifier(). In our model, the values of parameters are listed below. \n",
    "1. The number of trees $T$ is set as ``num_estimators = 20``\n",
    "2. the number of subsampled features for each tree is $k =\\sqrt{d}$, which corresponds to ``max_features = \"sqrt\"`` in the code.\n",
    "3. The maximum depth of each tree is ``max_depth = 6``.\n",
    "\n",
    "We will not use the pruning technique for each tree in the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier(object):\n",
    "    '''\n",
    "    This class is for random forest classification\n",
    "\n",
    "    Attributes:\n",
    "        - criterion: a function used as the criterion of classification tree\n",
    "        - num_estimators: the number of trees in the random forest \n",
    "        - tree: a nested dictionary representing the decision tree structure\n",
    "        - max_depth: the parameter to control the depth of tree. If the depth is larger than max_depth, we will stop splitting.\n",
    "        - max_feature: the number of selected features to build decision tree\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 num_estimators,\n",
    "                 random_state,\n",
    "                 criterion=gini_index,\n",
    "                 max_depth=None,\n",
    "                 max_features=\"sqrt\"):\n",
    "        self.num_estimators = num_estimators\n",
    "        self.random_state = random_state\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        function used to fit all trees in the random forest\n",
    "        \n",
    "        Args:\n",
    "            X - the features of the training samples\n",
    "            y - the labels of the training samples\n",
    "        Returns:\n",
    "            self.model_list - the model list containing `num_estimators` tree models\n",
    "        '''\n",
    "        n, d = X.shape\n",
    "        RandomState = np.random.RandomState(self.random_state)\n",
    "        self.model_list = []\n",
    "        for t in range(self.num_estimators):\n",
    "            random_seed = RandomState.randint(0, np.iinfo(np.int32).max)\n",
    "            ### draw a bootstrapped dataset from X\n",
    "            sample_index = RandomState.choice(np.arange(n), size=n, replace=True)\n",
    "            X_sampled = X[sample_index, :]\n",
    "            y_sampled = y[sample_index]\n",
    "            ### initialize the tree model by using DecisionTreeClassifier()\n",
    "            model = DecisionTreeClassifier(criterion=self.criterion,\n",
    "                                           max_depth=self.max_depth,\n",
    "                                           max_features=self.max_features,\n",
    "                                           random_seed=random_seed)\n",
    "            ### fit the tree model to the bootstrapped dataset by using DecisionTreeClassifier.fit()\n",
    "            model.fit(X_sampled, y_sampled)\n",
    "            self.model_list.append(model)\n",
    "        return self.model_list\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        function used to predict the labels of X\n",
    "        \n",
    "        Args:\n",
    "            X - the features of the test samples\n",
    "        Returns:\n",
    "            y_pred_label - the predicted labels of test samples\n",
    "        '''\n",
    "        n = X.shape[0]\n",
    "        y_pred = np.zeros([self.num_estimators, n], dtype=np.int32)\n",
    "        y_pred_label = np.zeros(n, dtype=np.int32)\n",
    "        ### use T tree classifiers to make predictions by using DecisionTreeClassifier.predict()\n",
    "        for i in range(self.num_estimators):\n",
    "            model_i = self.model_list[i]\n",
    "            y_pred[i, :] = model_i.predict(X)\n",
    "        ### take the majority vote \n",
    "        for i in range(n):\n",
    "            classes, count = np.unique(y_pred[:, i], return_counts=True)\n",
    "            y_pred_label[i] = classes[np.argmax(count)]\n",
    "        return y_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of the random forest is: 0.8025974025974026\n",
      "Testing accuracy of the random forest is: 0.65\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = t_t()\n",
    "model = RandomForestClassifier(num_estimators=20,\n",
    "                                   random_state=101,\n",
    "                                   criterion=gini_index,\n",
    "                                   max_depth=6)\n",
    "model.fit(X_train, y_train)\n",
    "y_train_hat = model.predict(X_train)\n",
    "y_test_hat = model.predict(X_test)\n",
    "acc_train = (y_train == y_train_hat).mean()\n",
    "acc_test = (y_test == y_test_hat).mean()\n",
    "print(\"Training accuracy of the random forest is:\", acc_train)\n",
    "print(\"Testing accuracy of the random forest is:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaboost(object):\n",
    "    '''\n",
    "    This class is for random forest classification\n",
    "\n",
    "    Attributes:\n",
    "        - criterion: a function used as the criterion of classification tree\n",
    "        - num_estimators: the number of iterations in the Adaboost\n",
    "        - tree: a nested dictionary representing the decision tree structure\n",
    "        - max_depth: the parameter to control the depth of tree. If the depth is larger than max_depth, we will stop splitting.\n",
    "        - model weight : a vector to store the weights of each model\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 num_estimators,\n",
    "                 criterion=gini_index,\n",
    "                 max_depth=None):\n",
    "        self.num_estimators = num_estimators\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        the function used to fit the decision tree, calculate the model $\\alpha_t$ and update the sample weights in \n",
    "        each iteration.\n",
    "        \n",
    "        Args:\n",
    "            X - the features of the training samples\n",
    "            y - the labels of the training samples\n",
    "        Returns:\n",
    "            self.model_list - the model list containing `num_estimators` tree models\n",
    "        '''\n",
    "        n, d = X.shape\n",
    "        sample_weight = np.ones(n) / n\n",
    "        self.model_weight = np.ones(self.num_estimators)\n",
    "        self.model_list = []\n",
    "        for t in range(self.num_estimators):\n",
    "            ### initialize the tree model by using DecisionTreeClassifier()\n",
    "            model_t = DecisionTreeClassifier(criterion=self.criterion,\n",
    "                                             max_depth=self.max_depth)\n",
    "            ### fit the tree model to the weighted samples by using DecisionTreeClassifier.fit()\n",
    "            model_t.fit(X, y, sample_weight=sample_weight)\n",
    "            ### make predictions by using DecisionTreeClassifier.predict()\n",
    "            y_pred_t = model_t.predict(X)\n",
    "            ### add the fitted model to the \"model_list\"\n",
    "            self.model_list.append(model_t)\n",
    "            ### calculate the weighted misclassification error $\\epsilon_t$\n",
    "            mis_classify_flag = np.where(y != y_pred_t)[0]\n",
    "            epsilon_t = np.sum(sample_weight[mis_classify_flag]) / np.sum(sample_weight)\n",
    "            ### calculate the model weight $\\alpha_t$\n",
    "            self.model_weight[t] = 0.5 * np.log(1 / epsilon_t - 1)\n",
    "            ### update the sample weight w_i\n",
    "            mis_classify_vec = np.zeros(n)\n",
    "            mis_classify_vec[mis_classify_flag] = 1\n",
    "            sample_weight = sample_weight * np.exp(self.model_weight[t] * mis_classify_vec)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        function used to predict the labels of X\n",
    "        \n",
    "        Args:\n",
    "            X - the features of the test samples\n",
    "        Returns:\n",
    "            y_pred_label - the predicted labels of test samples\n",
    "        '''\n",
    "        y_pred = np.zeros([self.num_estimators, X.shape[0]])\n",
    "        for t in range(self.num_estimators):\n",
    "            model = self.model_list[t]\n",
    "            y_pred_temp = model.predict(X)\n",
    "            y_pred_temp = y_pred_temp * self.model_weight[t]\n",
    "            y_pred[t, :] = y_pred_temp\n",
    "        y_pred_res = np.sum(y_pred, axis=0)\n",
    "        y_pred_label = -np.ones(X.shape[0])\n",
    "        y_pred_label[np.where(y_pred_res > 0)[0]] = 1\n",
    "        return y_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of Adaboost is: 0.9844155844155844\n",
      "Testing accuracy of Adaboost is: 0.6815789473684211\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = t_t()\n",
    "y_train[np.where(y_train == 0)[0]] = -1\n",
    "y_test[np.where(y_test == 0)[0]] = -1\n",
    "model = Adaboost(num_estimators=20, criterion=gini_index, max_depth=6)\n",
    "model.fit(X_train, y_train)\n",
    "y_train_hat = model.predict(X_train)\n",
    "y_test_hat = model.predict(X_test)\n",
    "acc_train = (y_train == y_train_hat).mean()\n",
    "acc_test = (y_test == y_test_hat).mean()\n",
    "print(\"Training accuracy of Adaboost is:\", acc_train)\n",
    "print(\"Testing accuracy of Adaboost is:\", acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93028d5495cf3fdad3791cfb45569ed1ffef5b94a8e8037ba1bdda77d837769f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
